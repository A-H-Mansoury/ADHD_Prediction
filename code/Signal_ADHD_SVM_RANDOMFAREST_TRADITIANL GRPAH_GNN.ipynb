{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPu7yFg6NqnFQsGokhfgtHB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qLdf0ON86qx","executionInfo":{"status":"ok","timestamp":1717173228351,"user_tz":420,"elapsed":6841,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"c19f1848-9054-4ecf-d54e-14b9a3db8a62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1FG2fJtZwQ9MedooOFfHCa3sa14GYVIi7\n","From (redirected): https://drive.google.com/uc?id=1FG2fJtZwQ9MedooOFfHCa3sa14GYVIi7&confirm=t&uuid=a49c2661-49cb-459e-97c8-8f08c1957976\n","To: /content/pearsonr.csv\n","100% 294M/294M [00:04<00:00, 61.5MB/s]\n"]}],"source":["!gdown 1FG2fJtZwQ9MedooOFfHCa3sa14GYVIi7"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n"],"metadata":{"id":"HpVDjIH_PXHB","executionInfo":{"status":"ok","timestamp":1717173250562,"user_tz":420,"elapsed":327,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cno74s6h9A-2","executionInfo":{"status":"ok","timestamp":1717169217957,"user_tz":420,"elapsed":4373,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"ff72e4d5-dd07-4707-94ce-37296314490a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["chunk_size = 10000\n","chunks = pd.read_csv(\"/content/drive/MyDrive/DM_project2/full_pearsonr.csv\", chunksize=chunk_size)\n","df = pd.concat(chunks, ignore_index=True)\n","df[\"DX Binary\"] = df[\"DX\"].apply(lambda x: 0 if x==0 else 1)\n","value_columns = [col for col in df.columns if col.startswith('Value_')]\n","df = df.dropna(how='any')\n","\n","np.random.seed(42)\n","\n","X = df[value_columns].values\n","y = df[\"DX Binary\"].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"],"metadata":{"id":"ZOvwRO5nOt_6","executionInfo":{"status":"ok","timestamp":1717169336236,"user_tz":420,"elapsed":118281,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/DM_project2/full_pearsonr.csv\")\n","df.head\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"yiPyNbT89wI-","executionInfo":{"status":"ok","timestamp":1717168233358,"user_tz":420,"elapsed":32902,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"a3d72e47-a0c9-405f-8867-d4d60ea221e7"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method NDFrame.head of                                                   File   Value_0   Value_1  \\\n","0    OHSU/5302451/sfnwmrda5302451_session_1_rest_2_...  0.170279 -0.357015   \n","1    OHSU/5302451/sfnwmrda5302451_session_1_rest_1_...  0.152777 -0.136541   \n","2    OHSU/5302451/sfnwmrda5302451_session_1_rest_3_...  0.061339  0.142587   \n","3    OHSU/1664335/sfnwmrda1664335_session_1_rest_1_...  0.234164 -0.390832   \n","4    OHSU/1664335/sfnwmrda1664335_session_1_rest_3_... -0.035030 -0.404082   \n","..                                                 ...       ...       ...   \n","232  OHSU/3358877/sfnwmrda3358877_session_1_rest_2_...  0.435861 -0.335554   \n","233  OHSU/3358877/sfnwmrda3358877_session_1_rest_3_...  0.510829 -0.012343   \n","234  OHSU/1536593/sfnwmrda1536593_session_1_rest_1_... -0.205585  0.167912   \n","235  OHSU/1536593/sfnwmrda1536593_session_1_rest_3_... -0.038178  0.164192   \n","236  OHSU/1536593/sfnwmrda1536593_session_1_rest_2_... -0.184669  0.111138   \n","\n","      Value_2   Value_3   Value_4   Value_5   Value_6   Value_7   Value_8  \\\n","0   -0.080553 -0.199137  0.119070 -0.248556  0.203942  0.076475 -0.307579   \n","1   -0.468412  0.407092 -0.279483  0.206026  0.288624 -0.424829  0.358432   \n","2   -0.375562  0.138847  0.403348  0.030845  0.201648 -0.463963  0.018966   \n","3   -0.042897 -0.287525 -0.369005 -0.463240  0.423153 -0.118169 -0.444646   \n","4   -0.266019 -0.054554 -0.198482 -0.117396  0.011500 -0.339786  0.053622   \n","..        ...       ...       ...       ...       ...       ...       ...   \n","232 -0.247041 -0.130681 -0.639822  0.126628 -0.068301 -0.068541 -0.016543   \n","233 -0.258274  0.536016 -0.283449  0.448765  0.123756 -0.009903 -0.293629   \n","234  0.418262  0.069701 -0.382346 -0.339661 -0.111209 -0.104731  0.054935   \n","235 -0.315495 -0.438683  0.444668 -0.129159 -0.478755  0.029799 -0.455024   \n","236  0.217697 -0.044190 -0.414610 -0.132631  0.373445  0.177786 -0.573442   \n","\n","     ...  Value_61417  Value_61418  Value_61419  Value_61420  Value_61421  \\\n","0    ...     0.136859    -0.184122    -0.023628    -0.182656     0.422924   \n","1    ...     0.251784     0.106533    -0.381012    -0.026503     0.225992   \n","2    ...     0.137037     0.224028    -0.127067    -0.224240     0.568172   \n","3    ...     0.479615    -0.255209     0.337163     0.331695     0.048842   \n","4    ...     0.484171    -0.157476    -0.251803    -0.369669     0.149649   \n","..   ...          ...          ...          ...          ...          ...   \n","232  ...    -0.058763    -0.272305    -0.040921     0.001235     0.316227   \n","233  ...     0.254415     0.578858     0.032135    -0.124622    -0.118524   \n","234  ...    -0.170098     0.003540     0.281789    -0.462178    -0.187748   \n","235  ...    -0.420850     0.242793     0.104937     0.323306    -0.370884   \n","236  ...     0.262007    -0.103187     0.405579     0.283231     0.417009   \n","\n","     Value_61422  Value_61423  Value_61424  ScanDir ID  DX  \n","0       0.417393     0.085780    -0.137589     5302451   3  \n","1       0.043158    -0.376233    -0.259121     5302451   3  \n","2       0.055972    -0.208200     0.270946     5302451   3  \n","3      -0.154432     0.260931    -0.267054     1664335   0  \n","4       0.437400    -0.585795    -0.240531     1664335   0  \n","..           ...          ...          ...         ...  ..  \n","232     0.412507     0.071605     0.147618     3358877   1  \n","233     0.151625     0.330822     0.232015     3358877   1  \n","234    -0.252533    -0.006931     0.018371     1536593   1  \n","235     0.357190    -0.250980    -0.398337     1536593   1  \n","236    -0.090420     0.270376     0.312128     1536593   1  \n","\n","[237 rows x 61428 columns]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.head</b><br/>def head(n: int=5) -&gt; NDFrameT</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py</a>Return the first `n` rows.\n","\n","This function returns the first `n` rows for the object based\n","on position. It is useful for quickly testing if your object\n","has the right type of data in it.\n","\n","For negative values of `n`, this function returns all rows except\n","the last `|n|` rows, equivalent to ``df[:n]``.\n","\n","If n is larger than the number of rows, this function returns all rows.\n","\n","Parameters\n","----------\n","n : int, default 5\n","    Number of rows to select.\n","\n","Returns\n","-------\n","same type as caller\n","    The first `n` rows of the caller object.\n","\n","See Also\n","--------\n","DataFrame.tail: Returns the last `n` rows.\n","\n","Examples\n","--------\n","&gt;&gt;&gt; df = pd.DataFrame({&#x27;animal&#x27;: [&#x27;alligator&#x27;, &#x27;bee&#x27;, &#x27;falcon&#x27;, &#x27;lion&#x27;,\n","...                    &#x27;monkey&#x27;, &#x27;parrot&#x27;, &#x27;shark&#x27;, &#x27;whale&#x27;, &#x27;zebra&#x27;]})\n","&gt;&gt;&gt; df\n","      animal\n","0  alligator\n","1        bee\n","2     falcon\n","3       lion\n","4     monkey\n","5     parrot\n","6      shark\n","7      whale\n","8      zebra\n","\n","Viewing the first 5 lines\n","\n","&gt;&gt;&gt; df.head()\n","      animal\n","0  alligator\n","1        bee\n","2     falcon\n","3       lion\n","4     monkey\n","\n","Viewing the first `n` lines (three in this case)\n","\n","&gt;&gt;&gt; df.head(3)\n","      animal\n","0  alligator\n","1        bee\n","2     falcon\n","\n","For negative values of `n`\n","\n","&gt;&gt;&gt; df.head(-3)\n","      animal\n","0  alligator\n","1        bee\n","2     falcon\n","3       lion\n","4     monkey\n","5     parrot</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 5559);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["#tresh hold\n","this part we want find tresh holde for echa row  and up tresh hold is 1 and down it is ziro"],"metadata":{"id":"WMeG2fH1_IKO"}},{"cell_type":"code","source":["first_row = df.iloc[0]\n","first_row\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41aeWP1K98g8","executionInfo":{"status":"ok","timestamp":1716401763643,"user_tz":420,"elapsed":6,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"72e552a1-f51d-48dc-9691-85f80085f304"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["File           OHSU/5302451/sfnwmrda5302451_session_1_rest_2_...\n","Value_0                                                 0.170279\n","Value_1                                                -0.357015\n","Value_2                                                -0.080553\n","Value_3                                                -0.199137\n","                                     ...                        \n","Value_61422                                             0.417393\n","Value_61423                                              0.08578\n","Value_61424                                            -0.137589\n","ScanDir ID                                               5302451\n","DX                                                             3\n","Name: 0, Length: 61428, dtype: object"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Assuming df is already loaded with your data\n","# Extract the first row\n","first_row = df.iloc[0, 1:]  # Exclude the 'File' column\n","\n","# Generate the x-axis values\n","x = range(len(first_row))\n","\n","# Convert the row to a list of y-axis values\n","y = first_row.values\n","\n","# Plotting\n","plt.figure(figsize=(10, 6))\n","plt.plot(x, y, marker='o', linestyle='-', color='b')\n","\n","# Adding labels and title\n","plt.xlabel('Abundant number')\n","plt.ylabel('Value')\n","plt.title('Plot of First Row Values')\n","plt.grid(True)\n","\n","# Show the plot\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"8ZMZdpjf_qs_","executionInfo":{"status":"ok","timestamp":1716401764525,"user_tz":420,"elapsed":886,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"a8ae8f8e-e2a1-4c77-b3c7-281d74fc30de"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Assuming df is already loaded with your data\n","# Extract the first row, excluding the 'File' column\n","first_row = df.iloc[0, 1:]  # Skip the 'File' column\n","\n","# Sort the values in ascending order\n","sorted_values = first_row.sort_values()\n","\n","# Generate the x-axis values\n","x = range(len(sorted_values))\n","\n","# Convert the sorted row to a list of y-axis values\n","y = sorted_values.values\n","\n","# Plotting\n","plt.figure(figsize=(10, 6))\n","plt.plot(x, y, marker='o', linestyle='-', color='b')\n","\n","# Adding labels and title\n","plt.xlabel('Abundant number')\n","plt.ylabel('Value')\n","plt.title('Plot of First Row Values (Sorted in Ascending Order)')\n","plt.grid(True)\n","\n","# Show the plot\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"NrTB-i9TBEYC","executionInfo":{"status":"ok","timestamp":1716401765235,"user_tz":420,"elapsed":714,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"f4fa77ad-378c-4c0e-a7c9-e5d11ff8a945"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["for 5302451"],"metadata":{"id":"dUrww2dXFk-C"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Assuming df is already loaded with your data\n","# Extract the first row, excluding the 'File' column\n","first_row = df.iloc[0, 1:]  # Skip the 'File' column\n","\n","# Define the bins from -1 to 1 with an interval of 0.1\n","bins = np.arange(-1, 1.1, 0.1)  # Create bins from -1 to 1 with a step of 0.1\n","\n","# Use pandas `cut` function to bin the data\n","binned_values = pd.cut(first_row, bins)\n","\n","# Count the number of values in each bin\n","bin_counts = binned_values.value_counts(sort=False)\n","\n","# Calculate the percentage for each bin\n","bin_percentages = (bin_counts / len(first_row)) * 100\n","\n","# Display the results\n","for bin_range, percentage in bin_percentages.items():\n","    print(f\"Range {bin_range}: {percentage:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RyvTK55AB-33","executionInfo":{"status":"ok","timestamp":1716401765235,"user_tz":420,"elapsed":7,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"1386056e-7637-41d7-a6d8-e3a83426f03c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Range (-1.0, -0.9]: 0.00%\n","Range (-0.9, -0.8]: 0.00%\n","Range (-0.8, -0.7]: 0.11%\n","Range (-0.7, -0.6]: 0.62%\n","Range (-0.6, -0.5]: 1.93%\n","Range (-0.5, -0.4]: 4.02%\n","Range (-0.4, -0.3]: 6.69%\n","Range (-0.3, -0.2]: 9.72%\n","Range (-0.2, -0.1]: 11.88%\n","Range (-0.1, -2.22e-16]: 13.53%\n","Range (-2.22e-16, 0.1]: 13.22%\n","Range (0.1, 0.2]: 12.11%\n","Range (0.2, 0.3]: 9.69%\n","Range (0.3, 0.4]: 7.07%\n","Range (0.4, 0.5]: 4.42%\n","Range (0.5, 0.6]: 2.63%\n","Range (0.6, 0.7]: 1.40%\n","Range (0.7, 0.8]: 0.67%\n","Range (0.8, 0.9]: 0.25%\n","Range (0.9, 1.0]: 0.04%\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Assuming df is already loaded with your data\n","# Extract the first row, excluding the 'File' column\n","first_row = df.iloc[0, 1:]  # Skip the 'File' column\n","\n","# Define the bins from -1 to 1 with an interval of 0.1\n","bins = np.arange(-1, 1.1, 0.1)  # Create bins from -1 to 1 with a step of 0.1\n","\n","# Use pandas `cut` function to bin the data\n","binned_values = pd.cut(first_row, bins)\n","\n","# Count the number of values in each bin\n","bin_counts = binned_values.value_counts(sort=False)\n","\n","# Calculate the percentage for each bin\n","bin_percentages = (bin_counts / len(first_row)) * 100\n","\n","# Plotting\n","plt.figure(figsize=(10, 6))\n","plt.bar(bin_percentages.index.astype(str), bin_percentages, color='b', width=0.8)\n","\n","# Adding labels and title\n","plt.xlabel('Value Ranges')\n","plt.ylabel('Percentage')\n","plt.title('Percentage of Values in Each Range from -1 to 1')\n","plt.xticks(rotation=45)\n","plt.grid(True)\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"FrYs2B3jCiYw","executionInfo":{"status":"ok","timestamp":1716401766104,"user_tz":420,"elapsed":874,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"76991701-dc94-499a-ba6e-dadc2594b4d6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["for 1664335"],"metadata":{"id":"GsK2V06cFc4L"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Assuming df is already loaded with your data\n","# Extract the first row, excluding the 'File' column\n","first_row = df.iloc[3, 1:]  # Skip the 'File' column\n","\n","# Define the bins from -1 to 1 with an interval of 0.1\n","bins = np.arange(-1, 1.1, 0.1)  # Create bins from -1 to 1 with a step of 0.1\n","\n","# Use pandas `cut` function to bin the data\n","binned_values = pd.cut(first_row, bins)\n","\n","# Count the number of values in each bin\n","bin_counts = binned_values.value_counts(sort=False)\n","\n","# Calculate the percentage for each bin\n","bin_percentages = (bin_counts / len(first_row)) * 100\n","\n","# Plotting\n","plt.figure(figsize=(10, 6))\n","plt.bar(bin_percentages.index.astype(str), bin_percentages, color='b', width=0.8)\n","\n","# Adding labels and title\n","plt.xlabel('Value Ranges')\n","plt.ylabel('Percentage')\n","plt.title('Percentage of Values in Each Range from -1 to 1')\n","plt.xticks(rotation=45)\n","plt.grid(True)\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"J18VudJwC_H0","executionInfo":{"status":"ok","timestamp":1716401766766,"user_tz":420,"elapsed":670,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"6ac2c23c-95d0-4fa5-f44d-695a38fe4e61"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Assuming df is already loaded with your data\n","# Extract the first row, excluding the 'File' column\n","first_row = df.iloc[3, 1:]  # Skip the 'File' column\n","\n","# Define the bins from -1 to 1 with an interval of 0.1\n","bins = np.arange(-1, 1.1, 0.1)  # Create bins from -1 to 1 with a step of 0.1\n","\n","# Use pandas `cut` function to bin the data\n","binned_values = pd.cut(first_row, bins)\n","\n","# Count the number of values in each bin\n","bin_counts = binned_values.value_counts(sort=False)\n","\n","# Calculate the percentage for each bin\n","bin_percentages = (bin_counts / len(first_row)) * 100\n","\n","# Display the results\n","for bin_range, percentage in bin_percentages.items():\n","    print(f\"Range {bin_range}: {percentage:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7egpTx5EgB6","executionInfo":{"status":"ok","timestamp":1716401766766,"user_tz":420,"elapsed":9,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"ff4ec6f9-8491-426b-d0b0-af791ee7dde7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Range (-1.0, -0.9]: 0.00%\n","Range (-0.9, -0.8]: 0.01%\n","Range (-0.8, -0.7]: 0.13%\n","Range (-0.7, -0.6]: 0.94%\n","Range (-0.6, -0.5]: 2.55%\n","Range (-0.5, -0.4]: 5.14%\n","Range (-0.4, -0.3]: 7.79%\n","Range (-0.3, -0.2]: 10.38%\n","Range (-0.2, -0.1]: 11.83%\n","Range (-0.1, -2.22e-16]: 12.50%\n","Range (-2.22e-16, 0.1]: 11.90%\n","Range (0.1, 0.2]: 10.55%\n","Range (0.2, 0.3]: 8.32%\n","Range (0.3, 0.4]: 6.20%\n","Range (0.4, 0.5]: 4.51%\n","Range (0.5, 0.6]: 3.15%\n","Range (0.6, 0.7]: 2.13%\n","Range (0.7, 0.8]: 1.34%\n","Range (0.8, 0.9]: 0.54%\n","Range (0.9, 1.0]: 0.09%\n"]}]},{"cell_type":"markdown","source":["#convert data to matix"],"metadata":{"id":"f2DvYhLEGKBU"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","def retrieve_adjacency_matrix(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","        # Extract the filenames and values from the DataFrame\n","    filenames = df['File']\n","    values = df.drop('File', axis=1).values\n","    adjacency_matrices = []\n","    for i in range(len(filenames)):        # Retrieve the upper triangle values from the row\n","        upper_triangle_values = values[i]\n","        # Calculate the size of the adjacency matrix\n","        n = int(np.sqrt(2 * len(upper_triangle_values) + 0.25) - 0.5)\n","                # Create a zero-filled matrix\n","        adjacency_matrix = np.zeros((n, n))\n","        # Fill the upper triangle of the adjacency matrix\n","        row = 0\n","        for j in range(n):\n","          for k in range(j+1, n):\n","                adjacency_matrix[j, k] = upper_triangle_values[row]\n","                row += 1\n","                # Transpose the upper triangle to fill the lower triangle\n","        adjacency_matrix += adjacency_matrix.T\n","        # Append the adjacency matrix to the list\n","        adjacency_matrices.append((filenames[i], adjacency_matrix))\n","    return adjacency_matrices\n","# Example usage\n","# adjacency_matrices = retrieve_adjacency_matrix(\"adjacency_matrices.csv\")# print(adjacency_matrices)"],"metadata":{"id":"FTC9hJtNEsYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["matrice=retrieve_adjacency_matrix(\"/content/pearsonr.csv\")"],"metadata":{"id":"TTVQrjz4HhtO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["matrice.shape()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"id":"DY6YQtPHH5Xf","executionInfo":{"status":"error","timestamp":1716392723960,"user_tz":420,"elapsed":39,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"93aa870f-45f2-4fc9-da5f-536ea36fe740"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'list' object has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-5e7a75e164fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"]}]},{"cell_type":"code","source":["for filename, matrix in adjacency_matrices:\n","    print(matrix)\n","    print(f\"Filename: {filename}, Matrix shape: {matrix.shape}\")"],"metadata":{"id":"wU-f3MkhK58p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_threshold(adjacency_matrices):\n","    thresholded_matrices = []\n","    for matrix in adjacency_matrices:\n","        # Apply thresholding: values > 0.5 or < -0.5 become 1, otherwise 0\n","        thresholded_matrix = np.where((matrix > 0.5) | (matrix < -0.5), 1, 0)\n","        thresholded_matrices.append(thresholded_matrix)\n","\n","    return thresholded_matrices\n"],"metadata":{"id":"CVlpx-_HNl6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the shapes and print all matrices to verify the result\n","for filename, matrix in thresholded_matrices:\n","    print(f\"Filename: {filename}, Matrix shape: {matrix.shape}\")\n","    print(matrix)  # Print the matrix to verify the thresholding\n"],"metadata":{"id":"3qvDB_iAOE4E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from concurrent.futures import ThreadPoolExecutor\n","from PIL import Image\n","\n","def retrieve_adjacency_matrix(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","\n","    # Extract the filenames and values from the DataFrame\n","    filenames = df['File']\n","    labels = df['DX'].tolist()\n","    values = df.drop(['File', 'ScanDir ID', 'DX'], axis=1).values\n","\n","\n","    adjacency_matrices = []\n","    for i in range(len(filenames)):\n","        # Retrieve the upper triangle values from the row and drop NaNs\n","        upper_triangle_values = values[i][~np.isnan(values[i])]\n","\n","        # Calculate the size of the adjacency matrix\n","        n = int(np.sqrt(2 * len(upper_triangle_values) + 0.25) - 0.5)\n","\n","        # Create a zero-filled matrix\n","        adjacency_matrix = np.zeros((n, n))\n","\n","        # Fill the upper triangle of the adjacency matrix\n","        row = 0\n","        for j in range(n):\n","            for k in range(j+1, n):\n","                adjacency_matrix[j, k] = upper_triangle_values[row]\n","                row += 1\n","\n","        # Transpose the upper triangle to fill the lower triangle\n","        adjacency_matrix += adjacency_matrix.T\n","\n","        if labels[i] == 0:\n","          label = 0\n","        else:\n","          label = 1\n","\n","        # Append the adjacency matrix and its label to the list\n","        adjacency_matrices.append((filenames[i], adjacency_matrix, label))\n","\n","    return adjacency_matrices\n","# Example usage\n","adjacency_matrices = retrieve_adjacency_matrix(\"/content/pearsonr.csv\")"],"metadata":{"id":"FfvcmnOA8kNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extracting only the adjacency matrices into a new list\n","adjacency_matrices = retrieve_adjacency_matrix(\"/content/pearsonr.csv\")"],"metadata":{"id":"z5r-7AorE07d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","x = [matrix for _, matrix, _ in adjacency_matrices]\n","\n","# Displaying the shape of the first adjacency matrix to verify\n","print(\"Shape of the first adjacency matrix:\", x[0].shape)\n","\n","# Optionally, display the shapes of all matrices to verify\n","for i, adjacency_matrix in enumerate(x):\n","    print(f\"Shape of adjacency matrix at index {i}: {adjacency_matrix.shape}\")\n","\n","# Apply the threshold function to the adjacency matrices\n","thresholded_matrices = apply_threshold(x)\n","\n","# Check the shapes and print a few matrices to verify the result\n","for i, matrix in enumerate(thresholded_matrices):\n","    print(f\"Thresholded matrix at index {i}, Matrix shape: {matrix.shape}\")\n","    print(matrix)  # Print the matrix to verify the thresholding\n","    if i >= 2:  # Adjust this condition to print more or fewer matrices\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBcP0vJI-28q","executionInfo":{"status":"ok","timestamp":1716401846968,"user_tz":420,"elapsed":699,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"c295c433-a9d8-45bb-fcd1-b5637087a204"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the first adjacency matrix: (350, 350)\n","Shape of adjacency matrix at index 0: (350, 350)\n","Shape of adjacency matrix at index 1: (350, 350)\n","Shape of adjacency matrix at index 2: (350, 350)\n","Shape of adjacency matrix at index 3: (350, 350)\n","Shape of adjacency matrix at index 4: (350, 350)\n","Shape of adjacency matrix at index 5: (350, 350)\n","Shape of adjacency matrix at index 6: (350, 350)\n","Shape of adjacency matrix at index 7: (350, 350)\n","Shape of adjacency matrix at index 8: (350, 350)\n","Shape of adjacency matrix at index 9: (350, 350)\n","Shape of adjacency matrix at index 10: (350, 350)\n","Shape of adjacency matrix at index 11: (350, 350)\n","Shape of adjacency matrix at index 12: (350, 350)\n","Shape of adjacency matrix at index 13: (350, 350)\n","Shape of adjacency matrix at index 14: (350, 350)\n","Shape of adjacency matrix at index 15: (350, 350)\n","Shape of adjacency matrix at index 16: (350, 350)\n","Shape of adjacency matrix at index 17: (350, 350)\n","Shape of adjacency matrix at index 18: (350, 350)\n","Shape of adjacency matrix at index 19: (350, 350)\n","Shape of adjacency matrix at index 20: (350, 350)\n","Shape of adjacency matrix at index 21: (350, 350)\n","Shape of adjacency matrix at index 22: (350, 350)\n","Shape of adjacency matrix at index 23: (350, 350)\n","Shape of adjacency matrix at index 24: (350, 350)\n","Shape of adjacency matrix at index 25: (350, 350)\n","Shape of adjacency matrix at index 26: (350, 350)\n","Shape of adjacency matrix at index 27: (350, 350)\n","Shape of adjacency matrix at index 28: (350, 350)\n","Shape of adjacency matrix at index 29: (350, 350)\n","Shape of adjacency matrix at index 30: (350, 350)\n","Shape of adjacency matrix at index 31: (350, 350)\n","Shape of adjacency matrix at index 32: (350, 350)\n","Shape of adjacency matrix at index 33: (350, 350)\n","Shape of adjacency matrix at index 34: (350, 350)\n","Shape of adjacency matrix at index 35: (350, 350)\n","Shape of adjacency matrix at index 36: (350, 350)\n","Shape of adjacency matrix at index 37: (350, 350)\n","Shape of adjacency matrix at index 38: (350, 350)\n","Shape of adjacency matrix at index 39: (350, 350)\n","Shape of adjacency matrix at index 40: (350, 350)\n","Shape of adjacency matrix at index 41: (350, 350)\n","Shape of adjacency matrix at index 42: (350, 350)\n","Shape of adjacency matrix at index 43: (350, 350)\n","Shape of adjacency matrix at index 44: (350, 350)\n","Shape of adjacency matrix at index 45: (350, 350)\n","Shape of adjacency matrix at index 46: (350, 350)\n","Shape of adjacency matrix at index 47: (350, 350)\n","Shape of adjacency matrix at index 48: (350, 350)\n","Shape of adjacency matrix at index 49: (350, 350)\n","Shape of adjacency matrix at index 50: (350, 350)\n","Shape of adjacency matrix at index 51: (350, 350)\n","Shape of adjacency matrix at index 52: (350, 350)\n","Shape of adjacency matrix at index 53: (350, 350)\n","Shape of adjacency matrix at index 54: (350, 350)\n","Shape of adjacency matrix at index 55: (350, 350)\n","Shape of adjacency matrix at index 56: (350, 350)\n","Shape of adjacency matrix at index 57: (350, 350)\n","Shape of adjacency matrix at index 58: (350, 350)\n","Shape of adjacency matrix at index 59: (350, 350)\n","Shape of adjacency matrix at index 60: (350, 350)\n","Shape of adjacency matrix at index 61: (350, 350)\n","Shape of adjacency matrix at index 62: (350, 350)\n","Shape of adjacency matrix at index 63: (350, 350)\n","Shape of adjacency matrix at index 64: (350, 350)\n","Shape of adjacency matrix at index 65: (350, 350)\n","Shape of adjacency matrix at index 66: (350, 350)\n","Shape of adjacency matrix at index 67: (350, 350)\n","Shape of adjacency matrix at index 68: (350, 350)\n","Shape of adjacency matrix at index 69: (350, 350)\n","Shape of adjacency matrix at index 70: (350, 350)\n","Shape of adjacency matrix at index 71: (350, 350)\n","Shape of adjacency matrix at index 72: (350, 350)\n","Shape of adjacency matrix at index 73: (350, 350)\n","Shape of adjacency matrix at index 74: (350, 350)\n","Shape of adjacency matrix at index 75: (350, 350)\n","Shape of adjacency matrix at index 76: (350, 350)\n","Shape of adjacency matrix at index 77: (350, 350)\n","Shape of adjacency matrix at index 78: (350, 350)\n","Shape of adjacency matrix at index 79: (350, 350)\n","Shape of adjacency matrix at index 80: (350, 350)\n","Shape of adjacency matrix at index 81: (350, 350)\n","Shape of adjacency matrix at index 82: (350, 350)\n","Shape of adjacency matrix at index 83: (350, 350)\n","Shape of adjacency matrix at index 84: (350, 350)\n","Shape of adjacency matrix at index 85: (350, 350)\n","Shape of adjacency matrix at index 86: (350, 350)\n","Shape of adjacency matrix at index 87: (350, 350)\n","Shape of adjacency matrix at index 88: (350, 350)\n","Shape of adjacency matrix at index 89: (350, 350)\n","Shape of adjacency matrix at index 90: (350, 350)\n","Shape of adjacency matrix at index 91: (350, 350)\n","Shape of adjacency matrix at index 92: (350, 350)\n","Shape of adjacency matrix at index 93: (350, 350)\n","Shape of adjacency matrix at index 94: (350, 350)\n","Shape of adjacency matrix at index 95: (350, 350)\n","Shape of adjacency matrix at index 96: (350, 350)\n","Shape of adjacency matrix at index 97: (350, 350)\n","Shape of adjacency matrix at index 98: (350, 350)\n","Shape of adjacency matrix at index 99: (350, 350)\n","Shape of adjacency matrix at index 100: (350, 350)\n","Shape of adjacency matrix at index 101: (350, 350)\n","Shape of adjacency matrix at index 102: (350, 350)\n","Shape of adjacency matrix at index 103: (350, 350)\n","Shape of adjacency matrix at index 104: (350, 350)\n","Shape of adjacency matrix at index 105: (350, 350)\n","Shape of adjacency matrix at index 106: (350, 350)\n","Shape of adjacency matrix at index 107: (350, 350)\n","Shape of adjacency matrix at index 108: (350, 350)\n","Shape of adjacency matrix at index 109: (350, 350)\n","Shape of adjacency matrix at index 110: (350, 350)\n","Shape of adjacency matrix at index 111: (350, 350)\n","Shape of adjacency matrix at index 112: (350, 350)\n","Shape of adjacency matrix at index 113: (350, 350)\n","Shape of adjacency matrix at index 114: (350, 350)\n","Shape of adjacency matrix at index 115: (350, 350)\n","Shape of adjacency matrix at index 116: (350, 350)\n","Shape of adjacency matrix at index 117: (350, 350)\n","Shape of adjacency matrix at index 118: (350, 350)\n","Shape of adjacency matrix at index 119: (350, 350)\n","Shape of adjacency matrix at index 120: (350, 350)\n","Shape of adjacency matrix at index 121: (350, 350)\n","Shape of adjacency matrix at index 122: (350, 350)\n","Shape of adjacency matrix at index 123: (350, 350)\n","Shape of adjacency matrix at index 124: (350, 350)\n","Shape of adjacency matrix at index 125: (350, 350)\n","Shape of adjacency matrix at index 126: (350, 350)\n","Shape of adjacency matrix at index 127: (350, 350)\n","Shape of adjacency matrix at index 128: (350, 350)\n","Shape of adjacency matrix at index 129: (350, 350)\n","Shape of adjacency matrix at index 130: (350, 350)\n","Shape of adjacency matrix at index 131: (350, 350)\n","Shape of adjacency matrix at index 132: (350, 350)\n","Shape of adjacency matrix at index 133: (350, 350)\n","Shape of adjacency matrix at index 134: (350, 350)\n","Shape of adjacency matrix at index 135: (350, 350)\n","Shape of adjacency matrix at index 136: (350, 350)\n","Shape of adjacency matrix at index 137: (350, 350)\n","Shape of adjacency matrix at index 138: (350, 350)\n","Shape of adjacency matrix at index 139: (350, 350)\n","Shape of adjacency matrix at index 140: (350, 350)\n","Shape of adjacency matrix at index 141: (350, 350)\n","Shape of adjacency matrix at index 142: (350, 350)\n","Shape of adjacency matrix at index 143: (350, 350)\n","Shape of adjacency matrix at index 144: (350, 350)\n","Shape of adjacency matrix at index 145: (350, 350)\n","Shape of adjacency matrix at index 146: (350, 350)\n","Shape of adjacency matrix at index 147: (350, 350)\n","Shape of adjacency matrix at index 148: (350, 350)\n","Shape of adjacency matrix at index 149: (350, 350)\n","Shape of adjacency matrix at index 150: (350, 350)\n","Shape of adjacency matrix at index 151: (350, 350)\n","Shape of adjacency matrix at index 152: (350, 350)\n","Shape of adjacency matrix at index 153: (350, 350)\n","Shape of adjacency matrix at index 154: (350, 350)\n","Shape of adjacency matrix at index 155: (350, 350)\n","Shape of adjacency matrix at index 156: (350, 350)\n","Shape of adjacency matrix at index 157: (350, 350)\n","Shape of adjacency matrix at index 158: (350, 350)\n","Shape of adjacency matrix at index 159: (350, 350)\n","Shape of adjacency matrix at index 160: (350, 350)\n","Shape of adjacency matrix at index 161: (350, 350)\n","Shape of adjacency matrix at index 162: (350, 350)\n","Shape of adjacency matrix at index 163: (350, 350)\n","Shape of adjacency matrix at index 164: (350, 350)\n","Shape of adjacency matrix at index 165: (350, 350)\n","Shape of adjacency matrix at index 166: (350, 350)\n","Shape of adjacency matrix at index 167: (350, 350)\n","Shape of adjacency matrix at index 168: (350, 350)\n","Shape of adjacency matrix at index 169: (350, 350)\n","Shape of adjacency matrix at index 170: (350, 350)\n","Shape of adjacency matrix at index 171: (350, 350)\n","Shape of adjacency matrix at index 172: (350, 350)\n","Shape of adjacency matrix at index 173: (350, 350)\n","Shape of adjacency matrix at index 174: (350, 350)\n","Shape of adjacency matrix at index 175: (350, 350)\n","Shape of adjacency matrix at index 176: (350, 350)\n","Shape of adjacency matrix at index 177: (350, 350)\n","Shape of adjacency matrix at index 178: (350, 350)\n","Shape of adjacency matrix at index 179: (350, 350)\n","Shape of adjacency matrix at index 180: (350, 350)\n","Shape of adjacency matrix at index 181: (350, 350)\n","Shape of adjacency matrix at index 182: (350, 350)\n","Shape of adjacency matrix at index 183: (350, 350)\n","Shape of adjacency matrix at index 184: (350, 350)\n","Shape of adjacency matrix at index 185: (350, 350)\n","Shape of adjacency matrix at index 186: (350, 350)\n","Shape of adjacency matrix at index 187: (350, 350)\n","Shape of adjacency matrix at index 188: (350, 350)\n","Shape of adjacency matrix at index 189: (350, 350)\n","Shape of adjacency matrix at index 190: (350, 350)\n","Shape of adjacency matrix at index 191: (350, 350)\n","Shape of adjacency matrix at index 192: (350, 350)\n","Shape of adjacency matrix at index 193: (350, 350)\n","Shape of adjacency matrix at index 194: (350, 350)\n","Shape of adjacency matrix at index 195: (350, 350)\n","Shape of adjacency matrix at index 196: (350, 350)\n","Shape of adjacency matrix at index 197: (350, 350)\n","Shape of adjacency matrix at index 198: (350, 350)\n","Shape of adjacency matrix at index 199: (350, 350)\n","Shape of adjacency matrix at index 200: (350, 350)\n","Shape of adjacency matrix at index 201: (350, 350)\n","Shape of adjacency matrix at index 202: (350, 350)\n","Shape of adjacency matrix at index 203: (350, 350)\n","Shape of adjacency matrix at index 204: (350, 350)\n","Shape of adjacency matrix at index 205: (350, 350)\n","Shape of adjacency matrix at index 206: (350, 350)\n","Shape of adjacency matrix at index 207: (350, 350)\n","Shape of adjacency matrix at index 208: (350, 350)\n","Shape of adjacency matrix at index 209: (350, 350)\n","Shape of adjacency matrix at index 210: (350, 350)\n","Shape of adjacency matrix at index 211: (350, 350)\n","Shape of adjacency matrix at index 212: (350, 350)\n","Shape of adjacency matrix at index 213: (350, 350)\n","Shape of adjacency matrix at index 214: (350, 350)\n","Shape of adjacency matrix at index 215: (350, 350)\n","Shape of adjacency matrix at index 216: (350, 350)\n","Shape of adjacency matrix at index 217: (350, 350)\n","Shape of adjacency matrix at index 218: (350, 350)\n","Shape of adjacency matrix at index 219: (350, 350)\n","Shape of adjacency matrix at index 220: (350, 350)\n","Shape of adjacency matrix at index 221: (350, 350)\n","Shape of adjacency matrix at index 222: (350, 350)\n","Shape of adjacency matrix at index 223: (350, 350)\n","Shape of adjacency matrix at index 224: (350, 350)\n","Shape of adjacency matrix at index 225: (350, 350)\n","Shape of adjacency matrix at index 226: (350, 350)\n","Shape of adjacency matrix at index 227: (350, 350)\n","Shape of adjacency matrix at index 228: (350, 350)\n","Shape of adjacency matrix at index 229: (350, 350)\n","Shape of adjacency matrix at index 230: (350, 350)\n","Shape of adjacency matrix at index 231: (350, 350)\n","Shape of adjacency matrix at index 232: (350, 350)\n","Shape of adjacency matrix at index 233: (350, 350)\n","Shape of adjacency matrix at index 234: (350, 350)\n","Shape of adjacency matrix at index 235: (350, 350)\n","Shape of adjacency matrix at index 236: (350, 350)\n","Thresholded matrix at index 0, Matrix shape: (350, 350)\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","Thresholded matrix at index 1, Matrix shape: (350, 350)\n","[[0 0 0 ... 0 0 0]\n"," [0 0 1 ... 0 0 0]\n"," [0 1 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","Thresholded matrix at index 2, Matrix shape: (350, 350)\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]}]},{"cell_type":"markdown","source":["#show data in graph"],"metadata":{"id":"Awl41N7j23vs"}},{"cell_type":"code","source":["!pip install networkx\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cDkJ_LeYNyTI","executionInfo":{"status":"ok","timestamp":1716394421171,"user_tz":420,"elapsed":9260,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"bb338ae6-5bd8-453f-bfc9-64b464a082a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n"]}]},{"cell_type":"code","source":["import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","def visualize_matrices_as_graphs(filenames, matrices, labels):\n","    for filename, matrix, label in zip(filenames, matrices, labels):\n","        print(f\"Filename: {filename}, Matrix shape: {matrix.shape}, Label: {label}\")\n","\n","        # Create an empty graph\n","        G = nx.Graph()\n","\n","        # Add edges to the graph based on the adjacency matrix\n","        for i in range(matrix.shape[0]):\n","            for j in range(i + 1, matrix.shape[1]):  # Consider only the upper triangle\n","                if matrix[i, j] == 1:\n","                    G.add_edge(i, j)\n","\n","        # Draw the graph with labels\n","        plt.figure(figsize=(8, 6))\n","        pos = nx.spring_layout(G)  # Layout for the nodes\n","        nx.draw(G, pos, with_labels=True, font_weight='bold', node_size=700, node_color='lightblue', edge_color='gray')\n","        nx.draw_networkx_labels(G, pos)\n","        plt.title(f\"Graph from {filename} (Label: {label})\")\n","        plt.show()\n","\n","\n"],"metadata":{"id":"ZkuwZ5j-3q8j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_file = '/content/pearsonr.csv'\n","adjacency_matrices = retrieve_adjacency_matrix(csv_file)\n","\n","\n","filenames = [filename for filename, _, _ in adjacency_matrices]\n","x = [matrix for _, matrix, _ in adjacency_matrices]\n","labels = [label for _, _, label in adjacency_matrices]\n","matrices = apply_threshold(x)\n","\n","visualize_matrices_as_graphs(filenames, matrices, labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19PK8D6PngxACkzX1NS3ozHMyFELHE5dL"},"id":"5grAUBY033LY","executionInfo":{"status":"error","timestamp":1716401948618,"user_tz":420,"elapsed":47413,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"010ac7a1-42d0-4427-f997-b6f75534ed89"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["#Graph Nerual Network"],"metadata":{"id":"mQpjj_IhlXvG"}},{"cell_type":"code","source":["!pip install torch-geometric\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVcUIRp9F104","executionInfo":{"status":"ok","timestamp":1717170039604,"user_tz":420,"elapsed":10396,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"dcd13c86-ce6f-4900-aebb-7282388b1ef9"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n"]}]},{"cell_type":"markdown","source":["#lode and preprose data"],"metadata":{"id":"ahKHFS-1pmC3"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","def retrieve_adjacency_matrix(csv_file):\n","    df = pd.read_csv(csv_file)\n","    filenames = df['File']\n","    labels = df['DX'].tolist()\n","    values = df.drop(['File', 'ScanDir ID', 'DX'], axis=1).values\n","\n","    adjacency_matrices = []\n","    for i in range(len(filenames)):\n","        upper_triangle_values = values[i][~np.isnan(values[i])]\n","        n = int(np.sqrt(2 * len(upper_triangle_values) + 0.25) - 0.5)\n","        adjacency_matrix = np.zeros((n, n))\n","\n","        row = 0\n","        for j in range(n):\n","            for k in range(j + 1, n):\n","                # Check if the current element is on the diagonal\n","                if j == k:\n","                    continue  # Skip setting diagonal elements\n","                adjacency_matrix[j, k] = upper_triangle_values[row]\n","                row += 1\n","        adjacency_matrices.append((filenames[i], adjacency_matrix, labels[i]))\n","\n","    return adjacency_matrices\n"],"metadata":{"id":"JhloRBQwopI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_threshold(adjacency_matrices):\n","    thresholded_matrices = []\n","    for filename, matrix, label in adjacency_matrices:\n","        thresholded_matrix = np.where((matrix > 0.6) | (matrix < -0.6), 1, 0)\n","        thresholded_matrices.append((filename, thresholded_matrix, label))\n","    return thresholded_matrices\n"],"metadata":{"id":"DBtPf0ZXp4Ns"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#big data load to matrix"],"metadata":{"id":"Shx9wu91Sxrj"}},{"cell_type":"code","source":["import numpy as np\n","\n","def upper_triangle_to_full_matrix(upper_tri_values):\n","    n = int(np.sqrt(2 * len(upper_tri_values) + 0.25) - 0.5)\n","    matrix = np.zeros((n, n))\n","\n","    index = 0\n","    for i in range(n):\n","        for j in range(i + 1, n):\n","            matrix[i, j] = upper_tri_values[index]\n","            matrix[j, i] = upper_tri_values[index]\n","            index += 1\n","    return matrix\n","\n","def convert_to_matrices(X):\n","    matrices = []\n","    for i in range(X.shape[0]):\n","        matrices.append(upper_triangle_to_full_matrix(X[i]))\n","    return np.array(matrices)\n","\n","# Convert X_train and X_test to full adjacency matrices\n","X_train_matrices = convert_to_matrices(X_train)\n","X_test_matrices = convert_to_matrices(X_test)\n"],"metadata":{"id":"KhzDIFsAS1dw","executionInfo":{"status":"ok","timestamp":1717169841855,"user_tz":420,"elapsed":52691,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def apply_threshold(adjacency_matrices, threshold=0.6):\n","    thresholded_matrices = []\n","    for matrix in adjacency_matrices:\n","        thresholded_matrix = np.where((matrix > threshold) | (matrix < -threshold), 1, 0)\n","        thresholded_matrices.append(thresholded_matrix)\n","    return np.array(thresholded_matrices)\n","\n","# Applying the threshold function to X_train_matrices and X_test_matrices\n","X_train_thresholded = apply_threshold(X_train_matrices)\n","X_test_thresholded = apply_threshold(X_test_matrices)\n"],"metadata":{"id":"T13YRVgtS1QG","executionInfo":{"status":"ok","timestamp":1717170019222,"user_tz":420,"elapsed":4047,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch_geometric.data import Data\n","from sklearn.model_selection import train_test_split\n","from torch_geometric.data import DataLoader\n"],"metadata":{"id":"RrC7wfw6vUtq","executionInfo":{"status":"ok","timestamp":1717170061933,"user_tz":420,"elapsed":16332,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","csv_file = '/content/pearsonr.csv'\n","adjacency_matrices = retrieve_adjacency_matrix(csv_file)\n","thresholded_matrices = apply_threshold(adjacency_matrices)\n","\n","# Convert labels to binary: 0 as class 0, and 1, 2, 3 as class 1\n","binary_labels = [0 if label == 0 else 1 for _, _, label in thresholded_matrices]\n","\n","# Create PyG data objects\n","data_list = []\n","for _, matrix, label in thresholded_matrices:\n","    edge_index = np.array(np.nonzero(matrix))\n","    edge_index = torch.tensor(edge_index, dtype=torch.long)\n","    print(matrix)\n","    x = torch.ones((matrix.shape[0], 1))  # Dummy node features\n","    y = torch.tensor([0 if label == 0 else 1], dtype=torch.long)\n","    data = Data(x=x, edge_index=edge_index, y=y)\n","    data_list.append(data)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I8ZbrHD7p7uG","executionInfo":{"status":"ok","timestamp":1716465294174,"user_tz":420,"elapsed":30049,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"2a82fe09-c650-46cf-ecf0-3560e1ffc1d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 1 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 1 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 1 1]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 1 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 1 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 1 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," ...\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 1 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[0 0 0 ... 1 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]}]},{"cell_type":"code","source":["data_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WRoLBE44Rjd9","executionInfo":{"status":"ok","timestamp":1716465294174,"user_tz":420,"elapsed":33,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"6a354d71-a828-48ef-dcf5-96a167a5b7f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Data(x=[350, 1], edge_index=[2, 1887], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1733], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1904], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3165], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3639], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2909], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1860], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1431], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2308], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3401], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5544], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4548], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3688], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 11516], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4334], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 8348], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3092], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3907], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1897], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3851], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3765], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2137], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2960], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5964], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4027], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2895], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1929], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1805], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2994], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1914], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1028], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2458], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1802], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3314], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2975], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1748], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4572], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 6382], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4027], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2290], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2643], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2793], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 10646], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5079], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 6308], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4039], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5674], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 6379], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3523], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2921], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2205], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1668], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2443], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1862], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4000], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5405], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3883], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3188], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 7981], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4351], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4687], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1787], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4183], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2491], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2630], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2363], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1513], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4260], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4713], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4490], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3669], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 8934], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4507], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3944], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3998], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5154], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2467], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2099], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1991], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2379], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2779], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2176], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5213], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3960], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4492], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3062], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5592], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3194], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2427], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2036], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2473], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2240], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2772], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2273], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3822], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2955], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3010], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1939], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2389], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1510], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2140], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3706], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 7583], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2451], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 7304], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2311], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2874], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4288], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2659], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5995], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3344], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3984], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5104], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5804], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4894], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3734], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4622], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3259], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3012], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1232], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1599], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1331], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4476], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1781], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3760], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2209], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2355], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2648], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3071], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2010], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1318], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3989], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 7249], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5190], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2790], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3319], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2229], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3108], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2838], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3784], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2168], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2526], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4176], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2510], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2055], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1493], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3426], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1996], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3574], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1653], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1958], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3515], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2634], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2414], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2965], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2063], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2324], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1629], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3955], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 6155], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5141], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4797], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3151], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 6157], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2984], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1611], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2044], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3514], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3755], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2324], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3015], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2929], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2975], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2599], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4570], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1661], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1849], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1763], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1516], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1959], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2859], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2976], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2291], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2687], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2795], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2154], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2500], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3693], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3910], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2027], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2561], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2063], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 6552], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3782], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5772], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1425], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2718], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1473], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3007], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1733], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3685], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3286], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 6971], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3771], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4303], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3429], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3062], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1976], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2494], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2572], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2284], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1771], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3995], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1794], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2471], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2581], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3742], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3356], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2032], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4597], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 7034], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 5038], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3086], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2316], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 1919], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3120], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2688], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2579], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3179], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3833], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4102], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 2128], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3861], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3067], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 3267], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 4942], y=[1]),\n"," Data(x=[350, 1], edge_index=[2, 6349], y=[1])]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["#work for big data"],"metadata":{"id":"0VAnnklkUI_6"}},{"cell_type":"code","source":["def create_pyg_data_objects(thresholded_matrices, labels):\n","    data_list = []\n","    for matrix, label in zip(thresholded_matrices, labels):\n","        edge_index = np.array(np.nonzero(matrix))\n","        edge_index = torch.tensor(edge_index, dtype=torch.long)\n","        x = torch.ones((matrix.shape[0], 1))  # Dummy node features\n","        y = torch.tensor([label], dtype=torch.long)\n","        data = Data(x=x, edge_index=edge_index, y=y)\n","        data_list.append(data)\n","    return data_list\n"],"metadata":{"id":"xbqf0VocULsU","executionInfo":{"status":"ok","timestamp":1717170341756,"user_tz":420,"elapsed":372,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# You will need to extract or define labels for your matrices as per your application\n","# Assuming y_train and y_test are your labels arrays that correspond to X_train_thresholded and X_test_thresholded\n","\n","X_train_pyg = create_pyg_data_objects(X_train_thresholded, y_train)\n","X_test_pyg = create_pyg_data_objects(X_test_thresholded, y_test)\n"],"metadata":{"id":"nkwMZ_7BVA9G","executionInfo":{"status":"ok","timestamp":1717170373320,"user_tz":420,"elapsed":1398,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch_geometric.data import DataLoader\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Create DataLoader for train and test sets directly\n","train_loader = DataLoader(X_train_pyg, batch_size=16, shuffle=True)\n","test_loader = DataLoader(X_test_pyg, batch_size=16, shuffle=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiD-6Wp6V5vs","executionInfo":{"status":"ok","timestamp":1717170579294,"user_tz":420,"elapsed":322,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"132915de-b70d-459a-a759-4c7330912b5f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]}]},{"cell_type":"code","source":["# Example training loop showing how to move data to the device\n","for data in train_loader:\n","    data = data.to(device)\n","    # Perform your training operations here\n","\n","# Example testing loop showing how to move data to the device\n","for data in test_loader:\n","    data = data.to(device)\n","    # Perform your testing operations here\n"],"metadata":{"id":"pCSnpYn8WB1j","executionInfo":{"status":"ok","timestamp":1717170612528,"user_tz":420,"elapsed":788,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["#finish part big data"],"metadata":{"id":"RrHF5ZODWCqI"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Split data into train and test sets\n","train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n","\n","# Define DataLoader for train and test sets\n","train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n","\n","# Move data to the device\n","for data in train_loader:\n","    data.to(device)\n","\n","for data in test_loader:\n","    data.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ua4c5L-BEYxA","executionInfo":{"status":"ok","timestamp":1716465427439,"user_tz":420,"elapsed":543,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"dc851804-c87f-40e1-de93-f0cf8c9c12c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]}]},{"cell_type":"markdown","source":["#myModel"],"metadata":{"id":"yzCvSvZIqxxB"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","\n","\n","class GCN(nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(1, 16)  # Input feature dimension is 1, output feature dimension is 16\n","        self.conv2 = GCNConv(16, 32)\n","        self.fc = nn.Linear(32, 2)  # Two classes\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = F.relu(x)\n","        x = torch_geometric.nn.global_mean_pool(x, data.batch)  # Global mean pooling\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)\n","\n","model = GCN()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","\n"],"metadata":{"id":"HJbisVVhqBmO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#model for big model"],"metadata":{"id":"T5HpZPrsWrhz"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","\n","class GCN(nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(1, 32)  # Reduced to one GCN layer, increased output features\n","        self.fc1 = nn.Linear(32, 64)  # Additional linear layer to increase model capacity\n","        self.fc2 = nn.Linear(64, 2)   # Two classes for final output\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = global_mean_pool(x, data.batch)  # Global mean pooling\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","model = GCN()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n"],"metadata":{"id":"cbE2VqJiWvO9","executionInfo":{"status":"ok","timestamp":1717170798038,"user_tz":420,"elapsed":328,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch_geometric.data import DataLoader\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","import numpy as np\n","\n","class GCN(nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(1, 16)\n","        self.fc1 = nn.Linear(16, 32)\n","        self.fc2 = nn.Linear(32, 64)\n","        self.fc3 = nn.Linear(64, 2)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = global_mean_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and loss criterion\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GCN().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6, 1.5], dtype=torch.float32).to(device))\n","\n","def randomize_learning_rate(optimizer, base_lr, epoch, max_lr=0.1, min_lr=0.005):\n","    # Randomly choose a learning rate within a specified range\n","    random_lr = np.random.uniform(low=min_lr, high=max_lr)\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = random_lr\n","\n","# Training loop\n","for epoch in range(1, 201):\n","    model.train()\n","    total_loss = 0\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = criterion(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    # Randomly adjust the learning rate\n","    randomize_learning_rate(optimizer, 0.01, epoch)\n","\n","    # Calculate metrics after training for each epoch\n","    accuracy, precision, recall, f1 = calculate_metrics(train_loader)\n","    print(f\"Epoch: {epoch:03d}, LR: {optimizer.param_groups[0]['lr']:.5f}, Loss: {total_loss / len(train_loader):.4f}, Acc: {accuracy:.4f}, Prec: {precision:.4f}, Rec: {recall:.4f}, F1: {f1:.4f}\")\n","\n","# Final evaluation on test data after all training is complete\n","test_accuracy = calculate_metrics(test_loader)\n","print(f\"Final Test Accuracy: {test_accuracy[0]:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xMMIWsjPg5r8","executionInfo":{"status":"error","timestamp":1717175848594,"user_tz":420,"elapsed":397043,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"1cee8d00-8452-43d8-8b0e-83633789c071"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, LR: 0.04058, Loss: 0.6948, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 002, LR: 0.09532, Loss: 0.6783, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 003, LR: 0.07454, Loss: 0.6774, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 004, LR: 0.06187, Loss: 0.6736, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 005, LR: 0.01982, Loss: 0.6756, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 006, LR: 0.01982, Loss: 0.6752, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 007, LR: 0.01052, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 008, LR: 0.08729, Loss: 0.6739, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 009, LR: 0.06211, Loss: 0.6753, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 010, LR: 0.07227, Loss: 0.6790, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 011, LR: 0.00696, Loss: 0.6758, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 012, LR: 0.09714, Loss: 0.6779, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 013, LR: 0.08408, Loss: 0.6755, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 014, LR: 0.02517, Loss: 0.6760, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 015, LR: 0.02227, Loss: 0.6745, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 016, LR: 0.02242, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 017, LR: 0.03390, Loss: 0.6753, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 018, LR: 0.05485, Loss: 0.6778, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 019, LR: 0.04603, Loss: 0.6733, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 020, LR: 0.03267, Loss: 0.6784, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 021, LR: 0.06313, Loss: 0.6752, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 022, LR: 0.01825, Loss: 0.6758, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 023, LR: 0.03275, Loss: 0.6758, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 024, LR: 0.03980, Loss: 0.6743, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 025, LR: 0.04833, Loss: 0.6762, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 026, LR: 0.07959, Loss: 0.6755, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 027, LR: 0.02397, Loss: 0.6791, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 028, LR: 0.05385, Loss: 0.6737, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 029, LR: 0.06128, Loss: 0.6755, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 030, LR: 0.00941, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 031, LR: 0.06272, Loss: 0.6742, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 032, LR: 0.02120, Loss: 0.6742, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 033, LR: 0.01118, Loss: 0.6756, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 034, LR: 0.09514, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 035, LR: 0.09674, Loss: 0.6770, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 036, LR: 0.08180, Loss: 0.6741, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 037, LR: 0.03394, Loss: 0.6769, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 038, LR: 0.01428, Loss: 0.6752, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 039, LR: 0.07000, Loss: 0.6742, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 040, LR: 0.04681, Loss: 0.6741, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 041, LR: 0.01659, Loss: 0.6766, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 042, LR: 0.05204, Loss: 0.6770, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 043, LR: 0.00827, Loss: 0.6777, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 044, LR: 0.09139, Loss: 0.6785, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 045, LR: 0.02958, Loss: 0.6769, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 046, LR: 0.06794, Loss: 0.6780, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 047, LR: 0.03461, Loss: 0.6758, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 048, LR: 0.05441, Loss: 0.6763, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 049, LR: 0.05694, Loss: 0.6763, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 050, LR: 0.02256, Loss: 0.6760, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 051, LR: 0.09711, Loss: 0.6759, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 052, LR: 0.07864, Loss: 0.6759, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 053, LR: 0.09425, Loss: 0.6764, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 054, LR: 0.09001, Loss: 0.6761, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 055, LR: 0.06180, Loss: 0.6770, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 056, LR: 0.09258, Loss: 0.6755, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 057, LR: 0.01341, Loss: 0.6768, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 058, LR: 0.02362, Loss: 0.6738, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 059, LR: 0.00930, Loss: 0.6755, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 060, LR: 0.03591, Loss: 0.6740, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 061, LR: 0.04192, Loss: 0.6752, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 062, LR: 0.03078, Loss: 0.6761, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 063, LR: 0.08373, Loss: 0.6745, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 064, LR: 0.03889, Loss: 0.6740, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 065, LR: 0.03169, Loss: 0.6734, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 066, LR: 0.05656, Loss: 0.6741, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 067, LR: 0.01839, Loss: 0.6742, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 068, LR: 0.08121, Loss: 0.6742, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 069, LR: 0.01208, Loss: 0.6754, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 070, LR: 0.09875, Loss: 0.6752, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 071, LR: 0.07836, Loss: 0.6768, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 072, LR: 0.02388, Loss: 0.6755, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 073, LR: 0.00552, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 074, LR: 0.08247, Loss: 0.6752, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 075, LR: 0.07215, Loss: 0.6765, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 076, LR: 0.07426, Loss: 0.6759, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 077, LR: 0.07827, Loss: 0.6750, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 078, LR: 0.01203, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 079, LR: 0.03905, Loss: 0.6758, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 080, LR: 0.01601, Loss: 0.6740, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 081, LR: 0.08699, Loss: 0.6739, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 082, LR: 0.06421, Loss: 0.6781, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 083, LR: 0.03644, Loss: 0.6753, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 084, LR: 0.01104, Loss: 0.6746, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 085, LR: 0.03454, Loss: 0.6757, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 086, LR: 0.03589, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 087, LR: 0.07431, Loss: 0.6749, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 088, LR: 0.06557, Loss: 0.6768, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 089, LR: 0.08929, Loss: 0.6754, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 090, LR: 0.04986, Loss: 0.6776, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 091, LR: 0.01636, Loss: 0.6751, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 092, LR: 0.07276, Loss: 0.6754, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 093, LR: 0.07727, Loss: 0.6762, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 094, LR: 0.05832, Loss: 0.6766, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 095, LR: 0.07824, Loss: 0.6751, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 096, LR: 0.05191, Loss: 0.6737, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 097, LR: 0.05466, Loss: 0.6764, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 098, LR: 0.04562, Loss: 0.6762, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 099, LR: 0.00741, Loss: 0.6752, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 100, LR: 0.01525, Loss: 0.6746, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 101, LR: 0.00799, Loss: 0.6737, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 102, LR: 0.06546, Loss: 0.6745, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 103, LR: 0.03486, Loss: 0.6763, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 104, LR: 0.05331, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 105, LR: 0.09122, Loss: 0.6759, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 106, LR: 0.02868, Loss: 0.6772, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 107, LR: 0.04399, Loss: 0.6750, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 108, LR: 0.07678, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 109, LR: 0.02674, Loss: 0.6732, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 110, LR: 0.01231, Loss: 0.6754, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 111, LR: 0.03253, Loss: 0.6741, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 112, LR: 0.02032, Loss: 0.6753, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 113, LR: 0.09332, Loss: 0.6767, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 114, LR: 0.08177, Loss: 0.6783, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 115, LR: 0.06517, Loss: 0.6762, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 116, LR: 0.08779, Loss: 0.6750, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 117, LR: 0.08135, Loss: 0.6759, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 118, LR: 0.02272, Loss: 0.6760, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 119, LR: 0.08979, Loss: 0.6745, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 120, LR: 0.05624, Loss: 0.6764, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 121, LR: 0.08171, Loss: 0.6750, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 122, LR: 0.09013, Loss: 0.6779, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 123, LR: 0.03521, Loss: 0.6752, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 124, LR: 0.01545, Loss: 0.6750, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 125, LR: 0.02665, Loss: 0.6758, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 126, LR: 0.04558, Loss: 0.6747, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 127, LR: 0.08271, Loss: 0.6765, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 128, LR: 0.08677, Loss: 0.6773, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 129, LR: 0.00566, Loss: 0.6766, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 130, LR: 0.05352, Loss: 0.6761, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 131, LR: 0.04465, Loss: 0.6753, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 132, LR: 0.02610, Loss: 0.6745, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 133, LR: 0.01639, Loss: 0.6743, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 134, LR: 0.03707, Loss: 0.6741, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 135, LR: 0.09458, Loss: 0.6774, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 136, LR: 0.03570, Loss: 0.6777, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 137, LR: 0.05429, Loss: 0.6756, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 138, LR: 0.07179, Loss: 0.6767, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 139, LR: 0.03954, Loss: 0.6770, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 140, LR: 0.09732, Loss: 0.6732, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 141, LR: 0.09643, Loss: 0.6786, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 142, LR: 0.02892, Loss: 0.6766, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 143, LR: 0.05224, Loss: 0.6757, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 144, LR: 0.03358, Loss: 0.6744, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 145, LR: 0.03206, Loss: 0.6750, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 146, LR: 0.00850, Loss: 0.6744, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 147, LR: 0.06291, Loss: 0.6736, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 148, LR: 0.05275, Loss: 0.6748, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 149, LR: 0.00989, Loss: 0.6759, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 150, LR: 0.03147, Loss: 0.6760, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 151, LR: 0.09129, Loss: 0.6746, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 152, LR: 0.02776, Loss: 0.6758, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 153, LR: 0.01877, Loss: 0.6765, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 154, LR: 0.05150, Loss: 0.6746, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 155, LR: 0.09864, Loss: 0.6762, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 156, LR: 0.02800, Loss: 0.6741, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 157, LR: 0.06885, Loss: 0.6774, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 158, LR: 0.07735, Loss: 0.6775, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 159, LR: 0.02758, Loss: 0.6743, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 160, LR: 0.07418, Loss: 0.6740, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 161, LR: 0.03994, Loss: 0.6745, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 162, LR: 0.06507, Loss: 0.6751, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 163, LR: 0.06519, Loss: 0.6743, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 164, LR: 0.05590, Loss: 0.6765, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 165, LR: 0.01358, Loss: 0.6762, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 166, LR: 0.08435, Loss: 0.6749, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n","Epoch: 167, LR: 0.03547, Loss: 0.6753, Acc: 0.3848, Prec: 0.3848, Rec: 1.0000, F1: 0.5558\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-01a9fa36c441>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-01a9fa36c441>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_jazxqsx9.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# End Message Forward Pre Hook #########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         out = self.message(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mx_j\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["!pip install torch torchvision\n","\n","!pip install torch-geometric\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQMCGVyerAF5","executionInfo":{"status":"ok","timestamp":1717176258354,"user_tz":420,"elapsed":138039,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"b7c66fce-1060-4109-8f67-5f5012e5d368"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MLVHAfPfrEFQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.data import DataLoader\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, num_features, num_classes):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(num_features, 16)\n","        self.conv2 = GCNConv(16, num_classes)  # num_classes is the output size\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        print(x)\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n"],"metadata":{"id":"wCXhaMuQp5dw","executionInfo":{"status":"ok","timestamp":1717177716461,"user_tz":420,"elapsed":358,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(X_train_pyg, batch_size=32, shuffle=True)\n","test_loader = DataLoader(X_test_pyg, batch_size=32, shuffle=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bT_rlhNgsqMp","executionInfo":{"status":"ok","timestamp":1717177717630,"user_tz":420,"elapsed":3,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"b5676e34-5bd4-44b6-bd98-bb41cdefbc6a"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GCN(num_features=350, num_classes=2).to(device)  # Adjust num_features according to your dataset specifics\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def train():\n","    model.train()\n","    total_loss = 0\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output[data.train_mask], data.y)  # Ensure your data objects have a train_mask and labels\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(train_loader)\n","\n","def test(loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    for data in loader:\n","        data = data.to(device)\n","        output = model(data)\n","        pred = output.argmax(dim=1)\n","        correct += pred.eq(data.y).sum().item()\n","        total += data.y.size(0)\n","    return correct / total\n","\n","# Training the model\n","for epoch in range(20):  # Adjust number of epochs as needed\n","    train_loss = train()\n","    test_acc = test(test_loader)\n","    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Test Acc: {100 * test_acc / len(test_loader.dataset):.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"id":"0is3BCcWwvxX","executionInfo":{"status":"error","timestamp":1717177719400,"user_tz":420,"elapsed":587,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"66d15233-afcf-49d9-bfe7-b40449259532"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.],\n","        [1.],\n","        [1.],\n","        ...,\n","        [1.],\n","        [1.],\n","        [1.]])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (11200x1 and 350x16)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-29f046b1e13a>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Adjust number of epochs as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Test Acc: {100 * test_acc / len(test_loader.dataset):.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-55-29f046b1e13a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure your data objects have a train_mask and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-53-ee2bf305400e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (11200x1 and 350x16)"]}]},{"cell_type":"markdown","source":["#finish big mdel"],"metadata":{"id":"NEy42kawg21Y"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch_geometric.data import Data, DataLoader\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","\n","class GCN(nn.Module):\n","    def __init__(self):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(1, 16)\n","        self.conv2 = GCNConv(16, 32)\n","        self.conv3 = GCNConv(32, 64)  # Adding an extra layer\n","        self.fc = nn.Linear(64, 2)  # Increased dimension to match the last GCN layer\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv3(x, edge_index)  # Additional layer\n","        x = F.relu(x)\n","        x = global_mean_pool(x, batch)\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)\n","\n","model = GCN()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)  # Try a smaller learning rate\n","criterion = nn.CrossEntropyLoss()\n","\n","def train():\n","    model.train()\n","    total_loss = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = criterion(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(train_loader)\n","\n","def test(loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for data in loader:\n","            out = model(data)\n","            pred = out.argmax(dim=1)\n","            correct += int((pred == data.y).sum())\n","    return correct / len(loader.dataset)\n","\n","for epoch in range(1, 201):\n","    train_loss = train()\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtCFLndVq5Gs","executionInfo":{"status":"ok","timestamp":1716405166836,"user_tz":420,"elapsed":237893,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"548b55db-6749-4ba6-ff8b-cded317e5f0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, Train Loss: 0.6983, Train Acc: 0.4497, Test Acc: 0.5833\n","Epoch: 002, Train Loss: 0.6942, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 003, Train Loss: 0.6922, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 004, Train Loss: 0.6899, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 005, Train Loss: 0.6894, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 006, Train Loss: 0.6898, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 007, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 008, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 009, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 010, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 011, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 012, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 013, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 014, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 015, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 016, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 017, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 018, Train Loss: 0.6877, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 019, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 020, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 021, Train Loss: 0.6887, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 022, Train Loss: 0.6890, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 023, Train Loss: 0.6888, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 024, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 025, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 026, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 027, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 028, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 029, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 030, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 031, Train Loss: 0.6894, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 032, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 033, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 034, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 035, Train Loss: 0.6890, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 036, Train Loss: 0.6888, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 037, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 038, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 039, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 040, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 041, Train Loss: 0.6893, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 042, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 043, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 044, Train Loss: 0.6877, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 045, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 046, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 047, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 048, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 049, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 050, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 051, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 052, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 053, Train Loss: 0.6877, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 054, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 055, Train Loss: 0.6888, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 056, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 057, Train Loss: 0.6878, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 058, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 059, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 060, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 061, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 062, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 063, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 064, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 065, Train Loss: 0.6887, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 066, Train Loss: 0.6887, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 067, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 068, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 069, Train Loss: 0.6888, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 070, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 071, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 072, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 073, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 074, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 075, Train Loss: 0.6894, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 076, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 077, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 078, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 079, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 080, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 081, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 082, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 083, Train Loss: 0.6891, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 084, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 085, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 086, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 087, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 088, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 089, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 090, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 091, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 092, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 093, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 094, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 095, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 096, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 097, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 098, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 099, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 100, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 101, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 102, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 103, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 104, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 105, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 106, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 107, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 108, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 109, Train Loss: 0.6889, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 110, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 111, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 112, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 113, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 114, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 115, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 116, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 117, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 118, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 119, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 120, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 121, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 122, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 123, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 124, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 125, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 126, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 127, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 128, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 129, Train Loss: 0.6877, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 130, Train Loss: 0.6889, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 131, Train Loss: 0.6887, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 132, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 133, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 134, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 135, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 136, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 137, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 138, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 139, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 140, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 141, Train Loss: 0.6890, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 142, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 143, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 144, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 145, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 146, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 147, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 148, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 149, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 150, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 151, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 152, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 153, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 154, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 155, Train Loss: 0.6887, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 156, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 157, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 158, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 159, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 160, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 161, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 162, Train Loss: 0.6887, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 163, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 164, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 165, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 166, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 167, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 168, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 169, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 170, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 171, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 172, Train Loss: 0.6886, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 173, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 174, Train Loss: 0.6891, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 175, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 176, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 177, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 178, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 179, Train Loss: 0.6878, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 180, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 181, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 182, Train Loss: 0.6878, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 183, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 184, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 185, Train Loss: 0.6884, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 186, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 187, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 188, Train Loss: 0.6879, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 189, Train Loss: 0.6883, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 190, Train Loss: 0.6889, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 191, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 192, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 193, Train Loss: 0.6877, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 194, Train Loss: 0.6887, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 195, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 196, Train Loss: 0.6881, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 197, Train Loss: 0.6880, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 198, Train Loss: 0.6885, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 199, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n","Epoch: 200, Train Loss: 0.6882, Train Acc: 0.5503, Test Acc: 0.4167\n"]}]},{"cell_type":"markdown","source":["#Test what is doing"],"metadata":{"id":"uwN94z6C5_A7"}},{"cell_type":"code","source":["from torch_geometric.data import Data, DataLoader\n","import torch\n","\n","# Example dataset with multiple data points (replace with your actual data)\n","data_list = []\n","\n","# Example: Creating multiple data points\n","for i in range(10):  # Assuming you have 10 graphs\n","    x = torch.tensor([[1.0], [2.0], [3.0]], dtype=torch.float)  # Example node features\n","    edge_index = torch.tensor([[0, 1], [1, 2]], dtype=torch.long).t().contiguous()  # Example edge index\n","    y = torch.tensor([i % 2], dtype=torch.long)  # Example label: alternating 0 and 1\n","\n","    data = Data(x=x, edge_index=edge_index, y=y)\n","    data_list.append(data)\n","\n","# Create DataLoader for batching\n","batch_size = 2  # Adjust based on your needs\n","train_loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n"],"metadata":{"id":"BahnbooivJpS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","\n","class SimpleGCN(nn.Module):\n","    def __init__(self):\n","        super(SimpleGCN, self).__init__()\n","        self.conv1 = GCNConv(1, 16)  # Adjust input feature dimension as needed\n","        self.fc = nn.Linear(16, 2)  # Adjust based on the number of classes\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = global_mean_pool(x, batch)\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)\n","\n","model = SimpleGCN()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)  # Try different learning rates\n","criterion = nn.CrossEntropyLoss()\n"],"metadata":{"id":"zcTb9i3UrFch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","    model.train()\n","    total_loss = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = criterion(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(train_loader)  # Average loss\n","\n","def test(loader):\n","    model.eval()\n","    correct = 0\n","    for data in loader:\n","        out = model(data)\n","        pred = out.argmax(dim=1)\n","        correct += int((pred == data.y).sum())\n","    return correct / len(loader.dataset)\n","\n","# Train the model for a sufficient number of epochs\n","for epoch in range(1, 201):  # Increase if necessary\n","    train_loss = train()\n","    train_acc = test(train_loader)\n","    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGeOJ2jDuhHl","executionInfo":{"status":"ok","timestamp":1716407304842,"user_tz":420,"elapsed":10587,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"cc2eca0c-54ea-433a-ed27-7e721f13a958"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, Train Loss: 0.7057, Train Acc: 0.5000\n","Epoch: 002, Train Loss: 0.6954, Train Acc: 0.5000\n","Epoch: 003, Train Loss: 0.6934, Train Acc: 0.5000\n","Epoch: 004, Train Loss: 0.7035, Train Acc: 0.5000\n","Epoch: 005, Train Loss: 0.7121, Train Acc: 0.5000\n","Epoch: 006, Train Loss: 0.6969, Train Acc: 0.5000\n","Epoch: 007, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 008, Train Loss: 0.6949, Train Acc: 0.5000\n","Epoch: 009, Train Loss: 0.6977, Train Acc: 0.5000\n","Epoch: 010, Train Loss: 0.6955, Train Acc: 0.5000\n","Epoch: 011, Train Loss: 0.6969, Train Acc: 0.5000\n","Epoch: 012, Train Loss: 0.6962, Train Acc: 0.5000\n","Epoch: 013, Train Loss: 0.6974, Train Acc: 0.5000\n","Epoch: 014, Train Loss: 0.7041, Train Acc: 0.5000\n","Epoch: 015, Train Loss: 0.6958, Train Acc: 0.5000\n","Epoch: 016, Train Loss: 0.6933, Train Acc: 0.5000\n","Epoch: 017, Train Loss: 0.6987, Train Acc: 0.5000\n","Epoch: 018, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 019, Train Loss: 0.7027, Train Acc: 0.5000\n","Epoch: 020, Train Loss: 0.6981, Train Acc: 0.5000\n","Epoch: 021, Train Loss: 0.7000, Train Acc: 0.5000\n","Epoch: 022, Train Loss: 0.6977, Train Acc: 0.5000\n","Epoch: 023, Train Loss: 0.6958, Train Acc: 0.5000\n","Epoch: 024, Train Loss: 0.7046, Train Acc: 0.5000\n","Epoch: 025, Train Loss: 0.6971, Train Acc: 0.5000\n","Epoch: 026, Train Loss: 0.6961, Train Acc: 0.5000\n","Epoch: 027, Train Loss: 0.6974, Train Acc: 0.5000\n","Epoch: 028, Train Loss: 0.6965, Train Acc: 0.5000\n","Epoch: 029, Train Loss: 0.6951, Train Acc: 0.5000\n","Epoch: 030, Train Loss: 0.6965, Train Acc: 0.5000\n","Epoch: 031, Train Loss: 0.7009, Train Acc: 0.5000\n","Epoch: 032, Train Loss: 0.6971, Train Acc: 0.5000\n","Epoch: 033, Train Loss: 0.6989, Train Acc: 0.5000\n","Epoch: 034, Train Loss: 0.6945, Train Acc: 0.5000\n","Epoch: 035, Train Loss: 0.7001, Train Acc: 0.5000\n","Epoch: 036, Train Loss: 0.6951, Train Acc: 0.5000\n","Epoch: 037, Train Loss: 0.6986, Train Acc: 0.5000\n","Epoch: 038, Train Loss: 0.6969, Train Acc: 0.5000\n","Epoch: 039, Train Loss: 0.7044, Train Acc: 0.5000\n","Epoch: 040, Train Loss: 0.6956, Train Acc: 0.5000\n","Epoch: 041, Train Loss: 0.6951, Train Acc: 0.5000\n","Epoch: 042, Train Loss: 0.6983, Train Acc: 0.5000\n","Epoch: 043, Train Loss: 0.6983, Train Acc: 0.5000\n","Epoch: 044, Train Loss: 0.6953, Train Acc: 0.5000\n","Epoch: 045, Train Loss: 0.7006, Train Acc: 0.5000\n","Epoch: 046, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 047, Train Loss: 0.6988, Train Acc: 0.5000\n","Epoch: 048, Train Loss: 0.6964, Train Acc: 0.5000\n","Epoch: 049, Train Loss: 0.6954, Train Acc: 0.5000\n","Epoch: 050, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 051, Train Loss: 0.6981, Train Acc: 0.5000\n","Epoch: 052, Train Loss: 0.6989, Train Acc: 0.5000\n","Epoch: 053, Train Loss: 0.6966, Train Acc: 0.5000\n","Epoch: 054, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 055, Train Loss: 0.6973, Train Acc: 0.5000\n","Epoch: 056, Train Loss: 0.6954, Train Acc: 0.5000\n","Epoch: 057, Train Loss: 0.6968, Train Acc: 0.5000\n","Epoch: 058, Train Loss: 0.7070, Train Acc: 0.5000\n","Epoch: 059, Train Loss: 0.7016, Train Acc: 0.5000\n","Epoch: 060, Train Loss: 0.7099, Train Acc: 0.5000\n","Epoch: 061, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 062, Train Loss: 0.6964, Train Acc: 0.5000\n","Epoch: 063, Train Loss: 0.6968, Train Acc: 0.5000\n","Epoch: 064, Train Loss: 0.6953, Train Acc: 0.5000\n","Epoch: 065, Train Loss: 0.6950, Train Acc: 0.5000\n","Epoch: 066, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 067, Train Loss: 0.6955, Train Acc: 0.5000\n","Epoch: 068, Train Loss: 0.6935, Train Acc: 0.5000\n","Epoch: 069, Train Loss: 0.6981, Train Acc: 0.5000\n","Epoch: 070, Train Loss: 0.6958, Train Acc: 0.5000\n","Epoch: 071, Train Loss: 0.6970, Train Acc: 0.5000\n","Epoch: 072, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 073, Train Loss: 0.6947, Train Acc: 0.5000\n","Epoch: 074, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 075, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 076, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 077, Train Loss: 0.6982, Train Acc: 0.5000\n","Epoch: 078, Train Loss: 0.6933, Train Acc: 0.5000\n","Epoch: 079, Train Loss: 0.6989, Train Acc: 0.5000\n","Epoch: 080, Train Loss: 0.6973, Train Acc: 0.5000\n","Epoch: 081, Train Loss: 0.7064, Train Acc: 0.5000\n","Epoch: 082, Train Loss: 0.6949, Train Acc: 0.5000\n","Epoch: 083, Train Loss: 0.6947, Train Acc: 0.5000\n","Epoch: 084, Train Loss: 0.6965, Train Acc: 0.5000\n","Epoch: 085, Train Loss: 0.7022, Train Acc: 0.5000\n","Epoch: 086, Train Loss: 0.6974, Train Acc: 0.5000\n","Epoch: 087, Train Loss: 0.6946, Train Acc: 0.5000\n","Epoch: 088, Train Loss: 0.6967, Train Acc: 0.5000\n","Epoch: 089, Train Loss: 0.6952, Train Acc: 0.5000\n","Epoch: 090, Train Loss: 0.6973, Train Acc: 0.5000\n","Epoch: 091, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 092, Train Loss: 0.6982, Train Acc: 0.5000\n","Epoch: 093, Train Loss: 0.6960, Train Acc: 0.5000\n","Epoch: 094, Train Loss: 0.6933, Train Acc: 0.5000\n","Epoch: 095, Train Loss: 0.6944, Train Acc: 0.5000\n","Epoch: 096, Train Loss: 0.7032, Train Acc: 0.5000\n","Epoch: 097, Train Loss: 0.6957, Train Acc: 0.5000\n","Epoch: 098, Train Loss: 0.6943, Train Acc: 0.5000\n","Epoch: 099, Train Loss: 0.6952, Train Acc: 0.5000\n","Epoch: 100, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 101, Train Loss: 0.7028, Train Acc: 0.5000\n","Epoch: 102, Train Loss: 0.6972, Train Acc: 0.5000\n","Epoch: 103, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 104, Train Loss: 0.7015, Train Acc: 0.5000\n","Epoch: 105, Train Loss: 0.6943, Train Acc: 0.5000\n","Epoch: 106, Train Loss: 0.7001, Train Acc: 0.5000\n","Epoch: 107, Train Loss: 0.6966, Train Acc: 0.5000\n","Epoch: 108, Train Loss: 0.6949, Train Acc: 0.5000\n","Epoch: 109, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 110, Train Loss: 0.6985, Train Acc: 0.5000\n","Epoch: 111, Train Loss: 0.6970, Train Acc: 0.5000\n","Epoch: 112, Train Loss: 0.6986, Train Acc: 0.5000\n","Epoch: 113, Train Loss: 0.6934, Train Acc: 0.5000\n","Epoch: 114, Train Loss: 0.6967, Train Acc: 0.5000\n","Epoch: 115, Train Loss: 0.6947, Train Acc: 0.5000\n","Epoch: 116, Train Loss: 0.6958, Train Acc: 0.5000\n","Epoch: 117, Train Loss: 0.6953, Train Acc: 0.5000\n","Epoch: 118, Train Loss: 0.6963, Train Acc: 0.5000\n","Epoch: 119, Train Loss: 0.6965, Train Acc: 0.5000\n","Epoch: 120, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 121, Train Loss: 0.6960, Train Acc: 0.5000\n","Epoch: 122, Train Loss: 0.6963, Train Acc: 0.5000\n","Epoch: 123, Train Loss: 0.6964, Train Acc: 0.5000\n","Epoch: 124, Train Loss: 0.7014, Train Acc: 0.5000\n","Epoch: 125, Train Loss: 0.6943, Train Acc: 0.5000\n","Epoch: 126, Train Loss: 0.6968, Train Acc: 0.5000\n","Epoch: 127, Train Loss: 0.6976, Train Acc: 0.5000\n","Epoch: 128, Train Loss: 0.7027, Train Acc: 0.5000\n","Epoch: 129, Train Loss: 0.6967, Train Acc: 0.5000\n","Epoch: 130, Train Loss: 0.7058, Train Acc: 0.5000\n","Epoch: 131, Train Loss: 0.6936, Train Acc: 0.5000\n","Epoch: 132, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 133, Train Loss: 0.7003, Train Acc: 0.5000\n","Epoch: 134, Train Loss: 0.6946, Train Acc: 0.5000\n","Epoch: 135, Train Loss: 0.6977, Train Acc: 0.5000\n","Epoch: 136, Train Loss: 0.6960, Train Acc: 0.5000\n","Epoch: 137, Train Loss: 0.6975, Train Acc: 0.5000\n","Epoch: 138, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 139, Train Loss: 0.6958, Train Acc: 0.5000\n","Epoch: 140, Train Loss: 0.6947, Train Acc: 0.5000\n","Epoch: 141, Train Loss: 0.6957, Train Acc: 0.5000\n","Epoch: 142, Train Loss: 0.7004, Train Acc: 0.5000\n","Epoch: 143, Train Loss: 0.6954, Train Acc: 0.5000\n","Epoch: 144, Train Loss: 0.6980, Train Acc: 0.5000\n","Epoch: 145, Train Loss: 0.6967, Train Acc: 0.5000\n","Epoch: 146, Train Loss: 0.6983, Train Acc: 0.5000\n","Epoch: 147, Train Loss: 0.6978, Train Acc: 0.5000\n","Epoch: 148, Train Loss: 0.6942, Train Acc: 0.5000\n","Epoch: 149, Train Loss: 0.6941, Train Acc: 0.5000\n","Epoch: 150, Train Loss: 0.6956, Train Acc: 0.5000\n","Epoch: 151, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 152, Train Loss: 0.6950, Train Acc: 0.5000\n","Epoch: 153, Train Loss: 0.6992, Train Acc: 0.5000\n","Epoch: 154, Train Loss: 0.6964, Train Acc: 0.5000\n","Epoch: 155, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 156, Train Loss: 0.6966, Train Acc: 0.5000\n","Epoch: 157, Train Loss: 0.6966, Train Acc: 0.5000\n","Epoch: 158, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 159, Train Loss: 0.6931, Train Acc: 0.5000\n","Epoch: 160, Train Loss: 0.6972, Train Acc: 0.5000\n","Epoch: 161, Train Loss: 0.6946, Train Acc: 0.5000\n","Epoch: 162, Train Loss: 0.6977, Train Acc: 0.5000\n","Epoch: 163, Train Loss: 0.6960, Train Acc: 0.5000\n","Epoch: 164, Train Loss: 0.6968, Train Acc: 0.5000\n","Epoch: 165, Train Loss: 0.6987, Train Acc: 0.5000\n","Epoch: 166, Train Loss: 0.6963, Train Acc: 0.5000\n","Epoch: 167, Train Loss: 0.7043, Train Acc: 0.5000\n","Epoch: 168, Train Loss: 0.6982, Train Acc: 0.5000\n","Epoch: 169, Train Loss: 0.6986, Train Acc: 0.5000\n","Epoch: 170, Train Loss: 0.6939, Train Acc: 0.5000\n","Epoch: 171, Train Loss: 0.6994, Train Acc: 0.5000\n","Epoch: 172, Train Loss: 0.6961, Train Acc: 0.5000\n","Epoch: 173, Train Loss: 0.6965, Train Acc: 0.5000\n","Epoch: 174, Train Loss: 0.6960, Train Acc: 0.5000\n","Epoch: 175, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 176, Train Loss: 0.6945, Train Acc: 0.5000\n","Epoch: 177, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 178, Train Loss: 0.7008, Train Acc: 0.5000\n","Epoch: 179, Train Loss: 0.6952, Train Acc: 0.5000\n","Epoch: 180, Train Loss: 0.6944, Train Acc: 0.5000\n","Epoch: 181, Train Loss: 0.6938, Train Acc: 0.5000\n","Epoch: 182, Train Loss: 0.6938, Train Acc: 0.5000\n","Epoch: 183, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 184, Train Loss: 0.6932, Train Acc: 0.5000\n","Epoch: 185, Train Loss: 0.6958, Train Acc: 0.5000\n","Epoch: 186, Train Loss: 0.6961, Train Acc: 0.5000\n","Epoch: 187, Train Loss: 0.6960, Train Acc: 0.5000\n","Epoch: 188, Train Loss: 0.6948, Train Acc: 0.5000\n","Epoch: 189, Train Loss: 0.6963, Train Acc: 0.5000\n","Epoch: 190, Train Loss: 0.6943, Train Acc: 0.5000\n","Epoch: 191, Train Loss: 0.7012, Train Acc: 0.5000\n","Epoch: 192, Train Loss: 0.6959, Train Acc: 0.5000\n","Epoch: 193, Train Loss: 0.6944, Train Acc: 0.5000\n","Epoch: 194, Train Loss: 0.6952, Train Acc: 0.5000\n","Epoch: 195, Train Loss: 0.6940, Train Acc: 0.5000\n","Epoch: 196, Train Loss: 0.6947, Train Acc: 0.5000\n","Epoch: 197, Train Loss: 0.6945, Train Acc: 0.5000\n","Epoch: 198, Train Loss: 0.6933, Train Acc: 0.5000\n","Epoch: 199, Train Loss: 0.6945, Train Acc: 0.5000\n","Epoch: 200, Train Loss: 0.6963, Train Acc: 0.5000\n"]}]},{"cell_type":"code","source":["for data in train_loader:\n","    print(data)\n","    break  # Print the first batch of data to check\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Ow_UEpcvXAb","executionInfo":{"status":"ok","timestamp":1716407341883,"user_tz":420,"elapsed":441,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"89c6c579-4af6-4b14-daa6-2f546038616c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataBatch(x=[6, 1], edge_index=[2, 4], y=[2], batch=[6], ptr=[3])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class ComplexModel(nn.Module):\n","    def __init__(self):\n","        super(ComplexModel, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","        self.fc1 = nn.Linear(128 * 25, 256)  # Assuming the input length is 100\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 2)  # Output layer for binary classification\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.pool(self.relu(self.conv1(x)))\n","        x = self.pool(self.relu(self.conv2(x)))\n","        x = self.pool(self.relu(self.conv3(x)))\n","        x = x.view(-1, 128 * 25)  # Flatten the tensor\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","# Create a small subset for overfitting test\n","small_data_list = data_list[:2]  # Use only the first 2 graphs\n","small_train_loader = DataLoader(small_data_list, batch_size=1, shuffle=True)\n","\n","# Initialize the model, loss function, and optimizer\n","model = ComplexModel()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training function\n","def train():\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    for batch in small_train_loader:\n","        optimizer.zero_grad()\n","        output = model(batch.x.float())\n","        loss = criterion(output, batch.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        pred = output.argmax(dim=1)\n","        correct += (pred == batch.y).sum().item()\n","    return total_loss / len(small_train_loader), correct / len(small_train_loader.dataset)\n","\n","# Testing function\n","def test(loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for batch in loader:\n","            output = model(batch.x.float())\n","            pred = output.argmax(dim=1)\n","            correct += (pred == batch.y).sum().item()\n","    return correct / len(loader.dataset)\n","\n","# Train the model on the small subset\n","for epoch in range(1, 201):\n","    train_loss, train_acc = train()\n","    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n"],"metadata":{"id":"a4R1ApX1vbig","colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"status":"error","timestamp":1716408943318,"user_tz":420,"elapsed":452,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"91e4c1c9-53b1-46de-cdf6-7fa1900f20fc"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Given groups=1, weight of size [32, 1, 3], expected input[1, 350, 1] to have 1 channels, but got 350 channels instead","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-0567c08a9413>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Train the model on the small subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-55-0567c08a9413>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmall_train_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-55-0567c08a9413>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 306\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    307\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3], expected input[1, 350, 1] to have 1 channels, but got 350 channels instead"]}]},{"cell_type":"markdown","source":["#test"],"metadata":{"id":"Zzt7Gcl2GCw8"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n","        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n","        self.conv4 = GCNConv(hidden_dim, hidden_dim)\n","        self.conv5 = GCNConv(hidden_dim, hidden_dim)\n","        self.conv6 = GCNConv(hidden_dim, hidden_dim)\n","        self.conv7 = GCNConv(hidden_dim, hidden_dim)\n","        self.conv8 = GCNConv(hidden_dim, hidden_dim)\n","        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n","        self.dropout = torch.nn.Dropout(0.5)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv2(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv3(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv4(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv5(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv6(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv7(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv8(x, edge_index)\n","        x = F.relu(x)\n","        x = global_mean_pool(x, batch)\n","        x = self.lin(x)\n","        return x\n","\n","# Initialize the model, loss function, and optimizer\n","model = GCN(input_dim=1, hidden_dim=64, output_dim=2)\n","criterion = torch.nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n","\n","# Training function\n","def train():\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        output = model(data)\n","        target = F.one_hot(data.y, num_classes=2).float()\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * data.num_graphs\n","        pred = (output > 0).float()\n","        correct += (pred == target).all(dim=1).sum().item()\n","    return total_loss / len(train_loader.dataset), correct / len(train_loader.dataset)\n","\n","# Testing function\n","def test(loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for data in loader:\n","            output = model(data)\n","            pred = (output > 0).float()\n","            target = F.one_hot(data.y, num_classes=2).float()\n","            correct += (pred == target).all(dim=1).sum().item()\n","    return correct / len(loader.dataset)\n","\n","# Split data into train, validation, and test sets\n","train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","# Training loop with early stopping\n","best_val_acc = 0\n","last_improvement_epoch = 0\n","for epoch in range(1, 201):\n","    train_loss, train_acc = train()\n","    val_acc = test(val_loader)\n","    test_acc = test(test_loader)\n","    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n","\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        torch.save(model.state_dict(), 'best_model.pt')\n","        last_improvement_epoch = epoch\n","    else:\n","        if epoch - last_improvement_epoch > 10:\n","            print(\"Early stopping.\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R07r1iR4AGJs","executionInfo":{"status":"ok","timestamp":1716447251099,"user_tz":420,"elapsed":35672,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"bcb74f48-ec06-4544-905d-646e8a37b8e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, Train Loss: 0.6914, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 002, Train Loss: 0.6910, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 003, Train Loss: 0.6913, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 004, Train Loss: 0.6911, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 005, Train Loss: 0.6910, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 006, Train Loss: 0.6912, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 007, Train Loss: 0.6909, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 008, Train Loss: 0.6911, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 009, Train Loss: 0.6908, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 010, Train Loss: 0.6908, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 011, Train Loss: 0.6908, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 012, Train Loss: 0.6909, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Early stopping.\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, output_dim)\n","        self.dropout = torch.nn.Dropout(0.5)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv2(x, edge_index)\n","        x = global_mean_pool(x, batch)\n","        return x\n","\n","# Initialize the model, loss function, and optimizer\n","model = GCN(input_dim=1, hidden_dim=32, output_dim=2)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training function\n","def train():\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * data.num_graphs\n","        pred = output.argmax(dim=1)\n","        correct += pred.eq(data.y).sum().item()\n","    return total_loss / len(train_loader.dataset), correct / len(train_loader.dataset)\n","\n","# Testing function\n","def test(loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for data in loader:\n","            output = model(data)\n","            pred = output.argmax(dim=1)\n","            correct += pred.eq(data.y).sum().item()\n","    return correct / len(loader.dataset)\n","\n","# Split data into train, validation, and test sets\n","train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","# Training loop with early stopping\n","best_val_acc = 0\n","last_improvement_epoch = 0\n","for epoch in range(1, 201):\n","    train_loss, train_acc = train()\n","    val_acc = test(val_loader)\n","    test_acc = test(test_loader)\n","    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n","\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        torch.save(model.state_dict(), 'best_model.pt')\n","        last_improvement_epoch = epoch\n","    else:\n","        if epoch - last_improvement_epoch > 10:\n","            print(\"Early stopping.\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jtWnFzCtPPoT","executionInfo":{"status":"ok","timestamp":1716447418952,"user_tz":420,"elapsed":5070,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"7cb9f673-70ab-4aee-d212-1be3d3218923"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, Train Loss: 0.6932, Train Acc: 0.5118, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 002, Train Loss: 0.6929, Train Acc: 0.5176, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 003, Train Loss: 0.6929, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 004, Train Loss: 0.6918, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 005, Train Loss: 0.6910, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 006, Train Loss: 0.6914, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 007, Train Loss: 0.6941, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 008, Train Loss: 0.6907, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 009, Train Loss: 0.6913, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 010, Train Loss: 0.6899, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 011, Train Loss: 0.6910, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Epoch: 012, Train Loss: 0.6934, Train Acc: 0.5353, Val Acc: 0.6842, Test Acc: 0.4167\n","Early stopping.\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.data import Data, DataLoader\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# Assuming you have retrieved and preprocessed your adjacency matrices\n","# Define your adjacency matrix processing functions here\n","\n","# Assuming you have defined thresholded_matrices and binary_labels\n","# Generate some sample data\n","num_nodes = 350\n","data_list = []\n","for matrix, label in zip(thresholded_matrices, binary_labels):\n","    if isinstance(matrix, tuple):\n","        matrix = matrix[0]  # Access the numpy array inside the tuple\n","    print(matrix.shape)\n","\n","\n","\n","for matrix, label in zip(thresholded_matrices, binary_labels):\n","    edge_indices = np.transpose(np.nonzero(matrix))  # Get edge indices as a list of tuples\n","    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()  # Transpose and make contiguous\n","    x = torch.ones((matrix.shape[0], 1))  # Dummy node features\n","    y = torch.tensor(label, dtype=torch.long)\n","    data = Data(x=x, edge_index=edge_index, y=y)\n","    data_list.append(data)\n","\n","# Define your GCN model\n","class GCN(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n","        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n","        self.dropout = torch.nn.Dropout(0.5)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.conv2(x, edge_index)\n","        x = F.relu(x)\n","        x = global_mean_pool(x, batch)\n","        x = self.lin(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize the model, loss function, and optimizer\n","model = GCN(input_dim=num_nodes, hidden_dim=64, output_dim=2)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Split data into train, validation, and test sets\n","train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","# Training loop\n","for epoch in range(1, 201):\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * data.num_graphs\n","        pred = output.argmax(dim=1)\n","        correct += pred.eq(data.y).sum().item()\n","    train_loss = total_loss / len(train_loader.dataset)\n","    train_acc = correct / len(train_loader.dataset)\n","\n","    val_acc = test(val_loader)\n","    test_acc = test(test_loader)\n","\n","    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"1mV9W7mcGEiW","executionInfo":{"status":"error","timestamp":1716450425446,"user_tz":420,"elapsed":402,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"7eb6eaf4-8b1e-4a38-b682-43e1784063e0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'str' object has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-039cf5758f72>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Access the numpy array inside the tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"]}]},{"cell_type":"markdown","source":["part2"],"metadata":{"id":"AXb7Md8BcecJ"}},{"cell_type":"code","source":["def test(loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in loader:\n","            output = model(data)\n","            pred = output.argmax(dim=1)\n","            correct += pred.eq(data.y).sum().item()\n","            total += len(data.y)\n","    return correct / total\n"],"metadata":{"id":"Fza7kqW8c0Dg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import TransformerConv, global_mean_pool\n","from torch_geometric.data import Data, DataLoader\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# Check if GPU is available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define the Graph Transformer Network model\n","# Define the Graph Convolutional Network model\n","class GraphConvolutionalNetwork(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n","        super(GraphConvolutionalNetwork, self).__init__()\n","        self.convs = nn.ModuleList([\n","            GCNConv(input_dim, hidden_dim) if i == 0 else\n","            GCNConv(hidden_dim, hidden_dim)\n","            for i in range(num_layers)\n","        ])\n","        self.lin = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x.to(device), data.edge_index.to(device), data.batch.to(device)\n","        for conv in self.convs:\n","            x = F.relu(conv(x, edge_index))\n","        x = global_mean_pool(x, batch)\n","        x = self.lin(x)\n","        return x\n","# Move model to GPU\n","model = GraphTransformerNetwork(input_dim=1, hidden_dim=64, output_dim=2, num_layers=3).to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","# Training loop\n","for epoch in range(1, 2001):\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    total_samples = 0\n","    for data in train_loader:\n","        data = data.to(device)  # Move data to GPU\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * data.num_graphs\n","        pred = output.argmax(dim=1)\n","        correct += pred.eq(data.y).sum().item()\n","        total_samples += len(data.y)\n","    train_loss = total_loss / total_samples\n","    train_acc = correct / total_samples\n","\n","    # Print train loss and accuracy\n","    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n","\n","    # Evaluate on test set\n","    model.eval()\n","    test_correct = 0\n","    with torch.no_grad():\n","        for data in test_loader:\n","            data = data.to(device)\n","            output = model(data)\n","            pred = output.argmax(dim=1)\n","            test_correct += pred.eq(data.y).sum().item()\n","    test_acc = test_correct / len(test_loader.dataset)\n","\n","    # Print test accuracy\n","    print(f'Test Acc: {test_acc:.4f}')\n"],"metadata":{"id":"oo-amQMQIyGj","executionInfo":{"status":"error","timestamp":1716462244011,"user_tz":420,"elapsed":45682,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"97be391d-efc0-4952-b8a1-5e7b8c1ef635"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 001, Train Loss: 0.7316, Train Acc: 0.5397\n","Test Acc: 0.4167\n","Epoch: 002, Train Loss: 0.6967, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 003, Train Loss: 0.6919, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 004, Train Loss: 0.6963, Train Acc: 0.5344\n","Test Acc: 0.4167\n","Epoch: 005, Train Loss: 0.6901, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 006, Train Loss: 0.6904, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 007, Train Loss: 0.6895, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 008, Train Loss: 0.6908, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 009, Train Loss: 0.6892, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 010, Train Loss: 0.6905, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 011, Train Loss: 0.6889, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 012, Train Loss: 0.6885, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 013, Train Loss: 0.6918, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 014, Train Loss: 0.7030, Train Acc: 0.4286\n","Test Acc: 0.4167\n","Epoch: 015, Train Loss: 0.6890, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 016, Train Loss: 0.6907, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 017, Train Loss: 0.6907, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 018, Train Loss: 0.6885, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 019, Train Loss: 0.6891, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 020, Train Loss: 0.6888, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 021, Train Loss: 0.6886, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 022, Train Loss: 0.6887, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 023, Train Loss: 0.6894, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 024, Train Loss: 0.6894, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 025, Train Loss: 0.6885, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 026, Train Loss: 0.6887, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 027, Train Loss: 0.6884, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 028, Train Loss: 0.6884, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 029, Train Loss: 0.6885, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 030, Train Loss: 0.6893, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 031, Train Loss: 0.6889, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 032, Train Loss: 0.6882, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 033, Train Loss: 0.6894, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 034, Train Loss: 0.6890, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 035, Train Loss: 0.6908, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 036, Train Loss: 0.6891, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 037, Train Loss: 0.6889, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 038, Train Loss: 0.6888, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 039, Train Loss: 0.6901, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 040, Train Loss: 0.6883, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 041, Train Loss: 0.6885, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 042, Train Loss: 0.6885, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 043, Train Loss: 0.6881, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 044, Train Loss: 0.6890, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 045, Train Loss: 0.6903, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 046, Train Loss: 0.6890, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 047, Train Loss: 0.6887, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 048, Train Loss: 0.6882, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 049, Train Loss: 0.6893, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 050, Train Loss: 0.6883, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 051, Train Loss: 0.6889, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 052, Train Loss: 0.6888, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 053, Train Loss: 0.6885, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 054, Train Loss: 0.6884, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 055, Train Loss: 0.6892, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 056, Train Loss: 0.6889, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 057, Train Loss: 0.6897, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 058, Train Loss: 0.6899, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 059, Train Loss: 0.6883, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 060, Train Loss: 0.6881, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 061, Train Loss: 0.6887, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 062, Train Loss: 0.6913, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 063, Train Loss: 0.6877, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 064, Train Loss: 0.6888, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 065, Train Loss: 0.6883, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 066, Train Loss: 0.6885, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 067, Train Loss: 0.6892, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 068, Train Loss: 0.6891, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 069, Train Loss: 0.6879, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 070, Train Loss: 0.6891, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 071, Train Loss: 0.6889, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 072, Train Loss: 0.6896, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 073, Train Loss: 0.6886, Train Acc: 0.5503\n","Test Acc: 0.4167\n","Epoch: 074, Train Loss: 0.6882, Train Acc: 0.5503\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-9244c4e54563>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mtest_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'_BaseDataLoaderIter'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseDataLoaderIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#thirde part"],"metadata":{"id":"kcM7j9cNKieL"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","# Define the Graph Convolutional Network model\n","class GraphClassifier(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n","        super(GraphClassifier, self).__init__()\n","        self.convs = nn.ModuleList([\n","            GCNConv(input_dim, hidden_dim) if i == 0 else\n","            GCNConv(hidden_dim, hidden_dim)\n","            for i in range(num_layers)\n","        ])\n","        self.lin = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        for conv in self.convs:\n","            x = F.relu(conv(x, edge_index))\n","        x = global_mean_pool(x, batch)\n","        x = self.lin(x)\n","        return x\n","\n","# Assuming train_data and test_data are already defined and contain your graphs\n","\n","# Define hyperparameters\n","input_dim = 1  # Assuming each node has 1 feature\n","hidden_dim = 64  # Define the desired size of the hidden dimension\n","output_dim = 1  # Since you're performing binary classification\n","num_layers = 3  # Define the number of GCN layers\n","\n","# Check if GPU is available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Move data to the device\n","train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n","\n","# Initialize the model\n","model = GraphClassifier(input_dim, hidden_dim, output_dim, num_layers).to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train the model\n","# Train the model\n","for epoch in range(1, 201):  # Assuming you want to train for 200 epochs\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    total_samples = 0\n","    for data in train_loader:\n","        data = data.to(device)  # Move data to the device\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output.view(-1), data.y.float())  # Assuming data.y contains graph labels (0 or 1)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * data.num_graphs\n","        pred = torch.round(torch.sigmoid(output))  # Assuming output is logits, convert to predictions\n","        correct += pred.eq(data.y.view_as(pred)).sum().item()\n","        total_samples += len(data.y)\n","    train_loss = total_loss / total_samples\n","    train_acc = correct / total_samples\n","\n","    # Print train loss and accuracy for each epoch\n","    print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')"],"metadata":{"id":"BwztXoTvcmAT","colab":{"base_uri":"https://localhost:8080/","height":762},"executionInfo":{"status":"error","timestamp":1716465670460,"user_tz":420,"elapsed":19530,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"0fc5123a-f939-4691-bb0e-217ab20a1f6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Train Loss: 0.6988, Train Acc: 0.4550\n","Epoch: 2, Train Loss: 0.6901, Train Acc: 0.5503\n","Epoch: 3, Train Loss: 0.6896, Train Acc: 0.5503\n","Epoch: 4, Train Loss: 0.6902, Train Acc: 0.5503\n","Epoch: 5, Train Loss: 0.6906, Train Acc: 0.5503\n","Epoch: 6, Train Loss: 0.6906, Train Acc: 0.5503\n","Epoch: 7, Train Loss: 0.6905, Train Acc: 0.5503\n","Epoch: 8, Train Loss: 0.6909, Train Acc: 0.5503\n","Epoch: 9, Train Loss: 0.6902, Train Acc: 0.5503\n","Epoch: 10, Train Loss: 0.6906, Train Acc: 0.5503\n","Epoch: 11, Train Loss: 0.6904, Train Acc: 0.5503\n","Epoch: 12, Train Loss: 0.6904, Train Acc: 0.5503\n","Epoch: 13, Train Loss: 0.6896, Train Acc: 0.5503\n","Epoch: 14, Train Loss: 0.6898, Train Acc: 0.5503\n","Epoch: 15, Train Loss: 0.6898, Train Acc: 0.5503\n","Epoch: 16, Train Loss: 0.6898, Train Acc: 0.5503\n","Epoch: 17, Train Loss: 0.6895, Train Acc: 0.5503\n","Epoch: 18, Train Loss: 0.6901, Train Acc: 0.5503\n","Epoch: 19, Train Loss: 0.6900, Train Acc: 0.5503\n","Epoch: 20, Train Loss: 0.6898, Train Acc: 0.5503\n","Epoch: 21, Train Loss: 0.6899, Train Acc: 0.5503\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-03e695d71fc8>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming data.y contains graph labels (0 or 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#use SVM"],"metadata":{"id":"LSUNI3vAWzLA"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Step 1: Retrieve adjacency matrices and labels\n","csv_file = '/content/pearsonr.csv'\n","df = pd.read_csv(csv_file)\n","values = df.drop(['File', 'ScanDir ID', 'DX'], axis=1).values\n","print(values)\n","\n","# Step 2: Convert labels to binary: 0 as class 0, and 1, 2, 3 as class 1\n","labels = df['DX'].tolist()\n","binary_labels = [0 if label == 0 else 1 for label in labels]\n","\n","# Step 3: Convert graphs into feature vectors (e.g., using graph properties)\n","feature_vectors = values  # Placeholder for feature vectors\n","# You may need to implement the feature extraction method here if you are working with graph data\n","\n","# Step 4: Train/Test Split\n","X_train, X_test, y_train, y_test = train_test_split(feature_vectors, binary_labels, test_size=0.2, random_state=42)\n","\n","# Step 5: SVM Training\n","svm_classifier = SVC(kernel='rbf')  # Radial Basis Function (RBF) kernel is commonly used\n","svm_classifier.fit(X_train, y_train)\n","\n","# Step 6: Evaluation\n","y_pred = svm_classifier.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aSQm1f0Pmj6","executionInfo":{"status":"ok","timestamp":1716466583858,"user_tz":420,"elapsed":32233,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"edf71941-ad24-409d-8189-1f365c91b740"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.17027862 -0.35701525 -0.08055347 ...  0.4173933   0.08578031\n","  -0.13758905]\n"," [ 0.15277709 -0.13654059 -0.46841171 ...  0.04315812 -0.37623271\n","  -0.25912112]\n"," [ 0.06133869  0.14258701 -0.37556171 ...  0.05597208 -0.20820038\n","   0.27094561]\n"," ...\n"," [-0.20558536  0.16791151  0.41826215 ... -0.25253326 -0.0069313\n","   0.01837067]\n"," [-0.03817777  0.1641918  -0.31549454 ...  0.35718954 -0.25098017\n","  -0.39833662]\n"," [-0.18466942  0.11113794  0.21769725 ... -0.09041971  0.27037618\n","   0.31212801]]\n","Accuracy: 0.625\n"]}]},{"cell_type":"markdown","source":["#random forest"],"metadata":{"id":"O9TO-I6dYog3"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","import pandas as pd\n","\n","# Step 1: Retrieve adjacency matrices and labels\n","csv_file = '/content/pearsonr.csv'\n","df = pd.read_csv(csv_file)\n","values = df.drop(['File', 'ScanDir ID', 'DX'], axis=1).values\n","print(values)\n","\n","# Step 2: Convert labels to binary: 0 as class 0, and 1, 2, 3 as class 1\n","labels = df['DX'].tolist()\n","binary_labels = [0 if label == 0 else 1 for label in labels]\n","\n","# Step 3: Train/Test Split\n","X_train, X_test, y_train, y_test = train_test_split(values, binary_labels, test_size=0.2, random_state=42)\n","\n","# Step 4: Random Forest Training\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_classifier.fit(X_train, y_train)\n","\n","# Step 5: Evaluation\n","y_pred = rf_classifier.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kq5bOzHQW2nh","executionInfo":{"status":"ok","timestamp":1716466924946,"user_tz":420,"elapsed":28822,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"3d5afc80-15b0-4eed-837c-8a7b5a66e32a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.17027862 -0.35701525 -0.08055347 ...  0.4173933   0.08578031\n","  -0.13758905]\n"," [ 0.15277709 -0.13654059 -0.46841171 ...  0.04315812 -0.37623271\n","  -0.25912112]\n"," [ 0.06133869  0.14258701 -0.37556171 ...  0.05597208 -0.20820038\n","   0.27094561]\n"," ...\n"," [-0.20558536  0.16791151  0.41826215 ... -0.25253326 -0.0069313\n","   0.01837067]\n"," [-0.03817777  0.1641918  -0.31549454 ...  0.35718954 -0.25098017\n","  -0.39833662]\n"," [-0.18466942  0.11113794  0.21769725 ... -0.09041971  0.27037618\n","   0.31212801]]\n","Accuracy: 0.5833333333333334\n"]}]},{"cell_type":"markdown","source":["#use node2vec"],"metadata":{"id":"FmAQxk9QaDcu"}},{"cell_type":"code","source":[],"metadata":{"id":"UmEdgdfqZklE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#test Clasifier"],"metadata":{"id":"ooTCzkZFhMY8"}},{"cell_type":"code","source":["import networkx as nx\n","import numpy as np\n","\n","# Generate random graphs\n","num_graphs = 30\n","num_nodes = 200\n","\n","random_graphs = []\n","for _ in range(num_graphs):\n","    # Generate a random graph\n","    G = nx.gnm_random_graph(num_nodes, num_nodes * 2)  # Erdős-Rényi model with n=200 and m=400\n","    # Assign a random label (0 or 1) to the graph\n","    label = np.random.randint(2)\n","    random_graphs.append((G, label))\n","\n","print(\"Generated\", num_graphs, \"random graphs.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5_1oG95hRFJ","executionInfo":{"status":"ok","timestamp":1716469071694,"user_tz":420,"elapsed":975,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"d2425104-8ef9-434c-db86-e3727a05a582"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated 30 random graphs.\n"]}]},{"cell_type":"code","source":["import networkx as nx\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch_geometric.data import Data, DataLoader\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","\n","# Generate random graphs\n","num_graphs = 30\n","num_nodes = 200\n","\n","random_graphs = []\n","for _ in range(num_graphs):\n","    # Generate a random graph\n","    G = nx.gnm_random_graph(num_nodes, num_nodes * 2)  # Erdős-Rényi model with n=200 and m=400\n","    # Assign a random label (0 or 1) to the graph\n","    label = np.random.randint(2)\n","    random_graphs.append((G, label))\n","\n","print(\"Generated\", num_graphs, \"random graphs.\")\n","\n","# Define your Graph Neural Network model\n","class GraphClassifier(nn.Module):\n","    def __init__(self):\n","        super(GraphClassifier, self).__init__()\n","        self.conv1 = GCNConv(1, 64)\n","        self.conv2 = GCNConv(64, 64)\n","        self.fc = nn.Linear(64, 2)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.relu(self.conv2(x, edge_index))\n","        x = global_mean_pool(x, data.batch)  # Global pooling\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# Create PyG data objects for random graphs\n","data_list = []\n","for G, label in random_graphs:\n","    # Convert networkx graph to PyG data object\n","    edge_index = torch.tensor(list(G.edges)).t().contiguous()\n","    x = torch.ones((len(G.nodes), 1), dtype=torch.float)  # Dummy node features\n","    y = torch.tensor([label], dtype=torch.long)\n","    data = Data(x=x, edge_index=edge_index, y=y)\n","    data_list.append(data)\n","\n","# Split data into training, validation, and test sets\n","train_size = int(0.6 * len(data_list))\n","val_size = int(0.2 * len(data_list))\n","test_size = len(data_list) - train_size - val_size\n","train_data, val_data, test_data = torch.utils.data.random_split(data_list, [train_size, val_size, test_size])\n","\n","# DataLoader for training, validation, and test sets\n","train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=4)\n","test_loader = DataLoader(test_data, batch_size=4)\n","\n","# Initialize model, loss function, and optimizer\n","model = GraphClassifier()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","# Training and evaluation\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    # Training loop\n","    model.train()\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = criterion(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Evaluation on validation set\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    with torch.no_grad():\n","        for data in val_loader:\n","            out = model(data)\n","            val_loss += criterion(out, data.y).item()\n","            _, predicted = torch.max(out, 1)\n","            val_total += data.y.size(0)\n","            val_correct += (predicted == data.y).sum().item()\n","    val_loss /= len(val_loader)\n","    val_accuracy = val_correct / val_total\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","# Evaluation on test set\n","model.eval()\n","test_loss = 0.0\n","test_correct = 0\n","test_total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        out = model(data)\n","        test_loss += criterion(out, data.y).item()\n","        _, predicted = torch.max(out, 1)\n","        test_total += data.y.size(0)\n","        test_correct += (predicted == data.y).sum().item()\n","test_loss /= len(test_loader)\n","test_accuracy = test_correct / test_total\n","\n","print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jn-ByCxjh3f8","executionInfo":{"status":"ok","timestamp":1716469201666,"user_tz":420,"elapsed":1795,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"763de890-f9a6-43e3-ae18-512628a9149c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated 30 random graphs.\n","Epoch 1/10, Validation Loss: 0.6179, Validation Accuracy: 0.8333\n","Epoch 2/10, Validation Loss: 0.5734, Validation Accuracy: 0.8333\n","Epoch 3/10, Validation Loss: 0.5601, Validation Accuracy: 0.8333\n","Epoch 4/10, Validation Loss: 0.5446, Validation Accuracy: 0.8333\n","Epoch 5/10, Validation Loss: 0.5760, Validation Accuracy: 0.8333\n","Epoch 6/10, Validation Loss: 0.5935, Validation Accuracy: 0.8333\n","Epoch 7/10, Validation Loss: 0.5860, Validation Accuracy: 0.8333\n","Epoch 8/10, Validation Loss: 0.5806, Validation Accuracy: 0.8333\n","Epoch 9/10, Validation Loss: 0.5573, Validation Accuracy: 0.8333\n","Epoch 10/10, Validation Loss: 0.5643, Validation Accuracy: 0.8333\n","Test Loss: 0.7125, Test Accuracy: 0.5000\n"]}]},{"cell_type":"markdown","source":["# work with adjectance matrix"],"metadata":{"id":"SVwPLky5jETW"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch_geometric.data import Data, DataLoader\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","\n","# Generate random adjacency matrices for graphs\n","num_graphs = 30\n","num_nodes = 200\n","\n","random_adj_matrices = []\n","for _ in range(num_graphs):\n","    # Generate a random adjacency matrix\n","    adj_matrix = np.random.randint(2, size=(num_nodes, num_nodes))\n","    # Make the matrix symmetric\n","    adj_matrix = np.triu(adj_matrix) + np.triu(adj_matrix, 1).T\n","    # Set the diagonal elements to zero\n","    np.fill_diagonal(adj_matrix, 0)\n","    random_adj_matrices.append(adj_matrix)\n","\n","print(\"Generated\", num_graphs, \"random adjacency matrices.\")\n","\n","# Define your Graph Neural Network model\n","class GraphClassifier(nn.Module):\n","    def __init__(self):\n","        super(GraphClassifier, self).__init__()\n","        self.conv1 = GCNConv(1, 64)\n","        self.conv2 = GCNConv(64, 128)\n","        self.conv3 = GCNConv(128, 128)\n","        self.fc = nn.Linear(128, 2)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = self.dropout(x)\n","        x = F.relu(self.conv2(x, edge_index))\n","        x = self.dropout(x)\n","        x = F.relu(self.conv3(x, edge_index))\n","        x = global_mean_pool(x, data.batch)  # Global pooling\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# Create PyG data objects for random adjacency matrices\n","data_list = []\n","for adj_matrix in random_adj_matrices:\n","    # Convert adjacency matrix to edge list\n","    edge_index = torch.tensor(np.argwhere(adj_matrix == 1).T, dtype=torch.long)\n","    # Dummy node features\n","    x = torch.ones((num_nodes, 1), dtype=torch.float)\n","    # Assign a random label (0 or 1) to the graph\n","    y = torch.tensor([np.random.randint(2)], dtype=torch.long)\n","    data = Data(x=x, edge_index=edge_index, y=y)\n","    data_list.append(data)\n","\n","# Split data into training, validation, and test sets\n","train_size = int(0.6 * len(data_list))\n","val_size = int(0.2 * len(data_list))\n","test_size = len(data_list) - train_size - val_size\n","train_data, val_data, test_data = torch.utils.data.random_split(data_list, [train_size, val_size, test_size])\n","\n","# DataLoader for training, validation, and test sets\n","train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=4)\n","test_loader = DataLoader(test_data, batch_size=4)\n","\n","# Initialize model, loss function, and optimizer\n","model = GraphClassifier()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # Learning rate scheduling\n","\n","# Training and evaluation\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    # Training loop\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = criterion(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Compute training accuracy\n","        _, predicted = torch.max(out, 1)\n","        train_total += data.y.size(0)\n","        train_correct += (predicted == data.y).sum().item()\n","        train_loss += loss.item()\n","\n","    train_loss /= len(train_loader)\n","    train_accuracy = train_correct / train_total\n","\n","    # Evaluation on validation set\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    with torch.no_grad():\n","        for data in val_loader:\n","            out = model(data)\n","            val_loss += criterion(out, data.y).item()\n","            _, predicted = torch.max(out, 1)\n","            val_total += data.y.size(0)\n","            val_correct += (predicted == data.y).sum().item()\n","    val_loss /= len(val_loader)\n","    val_accuracy = val_correct / val_total\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    scheduler.step()  # Update learning rate scheduler\n","\n","# Evaluation on test set\n","model.eval()\n","test_loss = 0.0\n","test_correct = 0\n","test_total = 0\n","with torch.no_grad():\n","    for data in test_loader:\n","        out = model(data)\n","        test_loss += criterion(out, data.y).item()\n","        _, predicted = torch.max(out, 1)\n","        test_total += data.y.size(0)\n","        test_correct += (predicted == data.y).sum().item()\n","test_loss /= len(test_loader)\n","test_accuracy = test_correct / test_total\n","\n","print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zx1seCJRiCpa","executionInfo":{"status":"ok","timestamp":1716469892745,"user_tz":420,"elapsed":162075,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"ef96feef-b6ed-43d0-bbd4-606d64a52859"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated 30 random adjacency matrices.\n","Epoch 1/100, Train Loss: 0.6902, Train Accuracy: 0.6111, Validation Loss: 0.8663, Validation Accuracy: 0.5000\n","Epoch 2/100, Train Loss: 0.6705, Train Accuracy: 0.6111, Validation Loss: 0.7412, Validation Accuracy: 0.5000\n","Epoch 3/100, Train Loss: 0.6746, Train Accuracy: 0.6111, Validation Loss: 0.7818, Validation Accuracy: 0.5000\n","Epoch 4/100, Train Loss: 0.6552, Train Accuracy: 0.6111, Validation Loss: 0.7709, Validation Accuracy: 0.5000\n","Epoch 5/100, Train Loss: 0.6516, Train Accuracy: 0.6111, Validation Loss: 0.7957, Validation Accuracy: 0.5000\n","Epoch 6/100, Train Loss: 0.6798, Train Accuracy: 0.6111, Validation Loss: 0.7885, Validation Accuracy: 0.5000\n","Epoch 7/100, Train Loss: 0.7179, Train Accuracy: 0.6111, Validation Loss: 0.8057, Validation Accuracy: 0.5000\n","Epoch 8/100, Train Loss: 0.6765, Train Accuracy: 0.6111, Validation Loss: 0.7532, Validation Accuracy: 0.5000\n","Epoch 9/100, Train Loss: 0.6735, Train Accuracy: 0.6111, Validation Loss: 0.7399, Validation Accuracy: 0.5000\n","Epoch 10/100, Train Loss: 0.6752, Train Accuracy: 0.6111, Validation Loss: 0.7360, Validation Accuracy: 0.5000\n","Epoch 11/100, Train Loss: 0.6632, Train Accuracy: 0.6111, Validation Loss: 0.7353, Validation Accuracy: 0.5000\n","Epoch 12/100, Train Loss: 0.6752, Train Accuracy: 0.6111, Validation Loss: 0.7416, Validation Accuracy: 0.5000\n","Epoch 13/100, Train Loss: 0.6768, Train Accuracy: 0.6111, Validation Loss: 0.7486, Validation Accuracy: 0.5000\n","Epoch 14/100, Train Loss: 0.6937, Train Accuracy: 0.6111, Validation Loss: 0.7551, Validation Accuracy: 0.5000\n","Epoch 15/100, Train Loss: 0.6563, Train Accuracy: 0.6111, Validation Loss: 0.7532, Validation Accuracy: 0.5000\n","Epoch 16/100, Train Loss: 0.6743, Train Accuracy: 0.6111, Validation Loss: 0.7537, Validation Accuracy: 0.5000\n","Epoch 17/100, Train Loss: 0.6742, Train Accuracy: 0.6111, Validation Loss: 0.7564, Validation Accuracy: 0.5000\n","Epoch 18/100, Train Loss: 0.6727, Train Accuracy: 0.6111, Validation Loss: 0.7609, Validation Accuracy: 0.5000\n","Epoch 19/100, Train Loss: 0.6726, Train Accuracy: 0.6111, Validation Loss: 0.7626, Validation Accuracy: 0.5000\n","Epoch 20/100, Train Loss: 0.6741, Train Accuracy: 0.6111, Validation Loss: 0.7661, Validation Accuracy: 0.5000\n","Epoch 21/100, Train Loss: 0.6946, Train Accuracy: 0.6111, Validation Loss: 0.7673, Validation Accuracy: 0.5000\n","Epoch 22/100, Train Loss: 0.6534, Train Accuracy: 0.6111, Validation Loss: 0.7651, Validation Accuracy: 0.5000\n","Epoch 23/100, Train Loss: 0.6532, Train Accuracy: 0.6111, Validation Loss: 0.7640, Validation Accuracy: 0.5000\n","Epoch 24/100, Train Loss: 0.6747, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Epoch 25/100, Train Loss: 0.6538, Train Accuracy: 0.6111, Validation Loss: 0.7679, Validation Accuracy: 0.5000\n","Epoch 26/100, Train Loss: 0.6512, Train Accuracy: 0.6111, Validation Loss: 0.7708, Validation Accuracy: 0.5000\n","Epoch 27/100, Train Loss: 0.6746, Train Accuracy: 0.6111, Validation Loss: 0.7787, Validation Accuracy: 0.5000\n","Epoch 28/100, Train Loss: 0.6737, Train Accuracy: 0.6111, Validation Loss: 0.7817, Validation Accuracy: 0.5000\n","Epoch 29/100, Train Loss: 0.6999, Train Accuracy: 0.6111, Validation Loss: 0.7787, Validation Accuracy: 0.5000\n","Epoch 30/100, Train Loss: 0.6732, Train Accuracy: 0.6111, Validation Loss: 0.7737, Validation Accuracy: 0.5000\n","Epoch 31/100, Train Loss: 0.6747, Train Accuracy: 0.6111, Validation Loss: 0.7716, Validation Accuracy: 0.5000\n","Epoch 32/100, Train Loss: 0.6730, Train Accuracy: 0.6111, Validation Loss: 0.7715, Validation Accuracy: 0.5000\n","Epoch 33/100, Train Loss: 0.6946, Train Accuracy: 0.6111, Validation Loss: 0.7698, Validation Accuracy: 0.5000\n","Epoch 34/100, Train Loss: 0.6533, Train Accuracy: 0.6111, Validation Loss: 0.7660, Validation Accuracy: 0.5000\n","Epoch 35/100, Train Loss: 0.6746, Train Accuracy: 0.6111, Validation Loss: 0.7674, Validation Accuracy: 0.5000\n","Epoch 36/100, Train Loss: 0.6952, Train Accuracy: 0.6111, Validation Loss: 0.7686, Validation Accuracy: 0.5000\n","Epoch 37/100, Train Loss: 0.6732, Train Accuracy: 0.6111, Validation Loss: 0.7653, Validation Accuracy: 0.5000\n","Epoch 38/100, Train Loss: 0.6718, Train Accuracy: 0.6111, Validation Loss: 0.7652, Validation Accuracy: 0.5000\n","Epoch 39/100, Train Loss: 0.6545, Train Accuracy: 0.6111, Validation Loss: 0.7631, Validation Accuracy: 0.5000\n","Epoch 40/100, Train Loss: 0.6947, Train Accuracy: 0.6111, Validation Loss: 0.7638, Validation Accuracy: 0.5000\n","Epoch 41/100, Train Loss: 0.6519, Train Accuracy: 0.6111, Validation Loss: 0.7634, Validation Accuracy: 0.5000\n","Epoch 42/100, Train Loss: 0.6535, Train Accuracy: 0.6111, Validation Loss: 0.7642, Validation Accuracy: 0.5000\n","Epoch 43/100, Train Loss: 0.6534, Train Accuracy: 0.6111, Validation Loss: 0.7649, Validation Accuracy: 0.5000\n","Epoch 44/100, Train Loss: 0.6931, Train Accuracy: 0.6111, Validation Loss: 0.7665, Validation Accuracy: 0.5000\n","Epoch 45/100, Train Loss: 0.6524, Train Accuracy: 0.6111, Validation Loss: 0.7662, Validation Accuracy: 0.5000\n","Epoch 46/100, Train Loss: 0.6722, Train Accuracy: 0.6111, Validation Loss: 0.7677, Validation Accuracy: 0.5000\n","Epoch 47/100, Train Loss: 0.6728, Train Accuracy: 0.6111, Validation Loss: 0.7680, Validation Accuracy: 0.5000\n","Epoch 48/100, Train Loss: 0.6732, Train Accuracy: 0.6111, Validation Loss: 0.7681, Validation Accuracy: 0.5000\n","Epoch 49/100, Train Loss: 0.6935, Train Accuracy: 0.6111, Validation Loss: 0.7682, Validation Accuracy: 0.5000\n","Epoch 50/100, Train Loss: 0.6724, Train Accuracy: 0.6111, Validation Loss: 0.7678, Validation Accuracy: 0.5000\n","Epoch 51/100, Train Loss: 0.6950, Train Accuracy: 0.6111, Validation Loss: 0.7674, Validation Accuracy: 0.5000\n","Epoch 52/100, Train Loss: 0.6736, Train Accuracy: 0.6111, Validation Loss: 0.7667, Validation Accuracy: 0.5000\n","Epoch 53/100, Train Loss: 0.6733, Train Accuracy: 0.6111, Validation Loss: 0.7666, Validation Accuracy: 0.5000\n","Epoch 54/100, Train Loss: 0.6735, Train Accuracy: 0.6111, Validation Loss: 0.7661, Validation Accuracy: 0.5000\n","Epoch 55/100, Train Loss: 0.6720, Train Accuracy: 0.6111, Validation Loss: 0.7658, Validation Accuracy: 0.5000\n","Epoch 56/100, Train Loss: 0.6529, Train Accuracy: 0.6111, Validation Loss: 0.7656, Validation Accuracy: 0.5000\n","Epoch 57/100, Train Loss: 0.6531, Train Accuracy: 0.6111, Validation Loss: 0.7657, Validation Accuracy: 0.5000\n","Epoch 58/100, Train Loss: 0.6525, Train Accuracy: 0.6111, Validation Loss: 0.7663, Validation Accuracy: 0.5000\n","Epoch 59/100, Train Loss: 0.6731, Train Accuracy: 0.6111, Validation Loss: 0.7670, Validation Accuracy: 0.5000\n","Epoch 60/100, Train Loss: 0.6530, Train Accuracy: 0.6111, Validation Loss: 0.7678, Validation Accuracy: 0.5000\n","Epoch 61/100, Train Loss: 0.6738, Train Accuracy: 0.6111, Validation Loss: 0.7682, Validation Accuracy: 0.5000\n","Epoch 62/100, Train Loss: 0.6523, Train Accuracy: 0.6111, Validation Loss: 0.7682, Validation Accuracy: 0.5000\n","Epoch 63/100, Train Loss: 0.6517, Train Accuracy: 0.6111, Validation Loss: 0.7684, Validation Accuracy: 0.5000\n","Epoch 64/100, Train Loss: 0.6513, Train Accuracy: 0.6111, Validation Loss: 0.7686, Validation Accuracy: 0.5000\n","Epoch 65/100, Train Loss: 0.6723, Train Accuracy: 0.6111, Validation Loss: 0.7692, Validation Accuracy: 0.5000\n","Epoch 66/100, Train Loss: 0.6712, Train Accuracy: 0.6111, Validation Loss: 0.7695, Validation Accuracy: 0.5000\n","Epoch 67/100, Train Loss: 0.6954, Train Accuracy: 0.6111, Validation Loss: 0.7696, Validation Accuracy: 0.5000\n","Epoch 68/100, Train Loss: 0.6515, Train Accuracy: 0.6111, Validation Loss: 0.7693, Validation Accuracy: 0.5000\n","Epoch 69/100, Train Loss: 0.6511, Train Accuracy: 0.6111, Validation Loss: 0.7694, Validation Accuracy: 0.5000\n","Epoch 70/100, Train Loss: 0.6515, Train Accuracy: 0.6111, Validation Loss: 0.7698, Validation Accuracy: 0.5000\n","Epoch 71/100, Train Loss: 0.6743, Train Accuracy: 0.6111, Validation Loss: 0.7700, Validation Accuracy: 0.5000\n","Epoch 72/100, Train Loss: 0.6732, Train Accuracy: 0.6111, Validation Loss: 0.7700, Validation Accuracy: 0.5000\n","Epoch 73/100, Train Loss: 0.6733, Train Accuracy: 0.6111, Validation Loss: 0.7701, Validation Accuracy: 0.5000\n","Epoch 74/100, Train Loss: 0.6513, Train Accuracy: 0.6111, Validation Loss: 0.7702, Validation Accuracy: 0.5000\n","Epoch 75/100, Train Loss: 0.6729, Train Accuracy: 0.6111, Validation Loss: 0.7703, Validation Accuracy: 0.5000\n","Epoch 76/100, Train Loss: 0.6736, Train Accuracy: 0.6111, Validation Loss: 0.7704, Validation Accuracy: 0.5000\n","Epoch 77/100, Train Loss: 0.6726, Train Accuracy: 0.6111, Validation Loss: 0.7704, Validation Accuracy: 0.5000\n","Epoch 78/100, Train Loss: 0.6726, Train Accuracy: 0.6111, Validation Loss: 0.7704, Validation Accuracy: 0.5000\n","Epoch 79/100, Train Loss: 0.6726, Train Accuracy: 0.6111, Validation Loss: 0.7703, Validation Accuracy: 0.5000\n","Epoch 80/100, Train Loss: 0.6731, Train Accuracy: 0.6111, Validation Loss: 0.7703, Validation Accuracy: 0.5000\n","Epoch 81/100, Train Loss: 0.6719, Train Accuracy: 0.6111, Validation Loss: 0.7702, Validation Accuracy: 0.5000\n","Epoch 82/100, Train Loss: 0.6523, Train Accuracy: 0.6111, Validation Loss: 0.7702, Validation Accuracy: 0.5000\n","Epoch 83/100, Train Loss: 0.6512, Train Accuracy: 0.6111, Validation Loss: 0.7703, Validation Accuracy: 0.5000\n","Epoch 84/100, Train Loss: 0.6526, Train Accuracy: 0.6111, Validation Loss: 0.7704, Validation Accuracy: 0.5000\n","Epoch 85/100, Train Loss: 0.6715, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Epoch 86/100, Train Loss: 0.6730, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Epoch 87/100, Train Loss: 0.6522, Train Accuracy: 0.6111, Validation Loss: 0.7706, Validation Accuracy: 0.5000\n","Epoch 88/100, Train Loss: 0.6725, Train Accuracy: 0.6111, Validation Loss: 0.7707, Validation Accuracy: 0.5000\n","Epoch 89/100, Train Loss: 0.6734, Train Accuracy: 0.6111, Validation Loss: 0.7707, Validation Accuracy: 0.5000\n","Epoch 90/100, Train Loss: 0.6956, Train Accuracy: 0.6111, Validation Loss: 0.7707, Validation Accuracy: 0.5000\n","Epoch 91/100, Train Loss: 0.6938, Train Accuracy: 0.6111, Validation Loss: 0.7707, Validation Accuracy: 0.5000\n","Epoch 92/100, Train Loss: 0.6730, Train Accuracy: 0.6111, Validation Loss: 0.7706, Validation Accuracy: 0.5000\n","Epoch 93/100, Train Loss: 0.6731, Train Accuracy: 0.6111, Validation Loss: 0.7706, Validation Accuracy: 0.5000\n","Epoch 94/100, Train Loss: 0.6718, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Epoch 95/100, Train Loss: 0.6518, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Epoch 96/100, Train Loss: 0.6731, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Epoch 97/100, Train Loss: 0.6951, Train Accuracy: 0.6111, Validation Loss: 0.7706, Validation Accuracy: 0.5000\n","Epoch 98/100, Train Loss: 0.6952, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Epoch 99/100, Train Loss: 0.6507, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Epoch 100/100, Train Loss: 0.6736, Train Accuracy: 0.6111, Validation Loss: 0.7705, Validation Accuracy: 0.5000\n","Test Loss: 0.7164, Test Accuracy: 0.3333\n"]}]},{"cell_type":"markdown","source":["#use vector of graphlet and dgree note"],"metadata":{"id":"OJNdBdpjrSYK"}},{"cell_type":"code","source":["import numpy as np\n","import networkx as nx\n","\n","# Function to compute subgraph centrality for a graph\n","def compute_subgraph_centrality(graph):\n","    subgraph_centrality = nx.algorithms.centrality.subgraph_centrality(graph)\n","    return list(subgraph_centrality.values())\n","\n","# Generate random graphs\n","num_graphs = 30\n","num_nodes = 200\n","graph_features = []\n","\n","for _ in range(num_graphs):\n","    # Generate a random graph\n","    G = nx.gnm_random_graph(num_nodes, num_nodes * 2)\n","    # Compute subgraph centrality\n","    subgraph_centrality = compute_subgraph_centrality(G)\n","    # Append subgraph centrality to feature vector\n","    feature_vector = np.array(subgraph_centrality)\n","    graph_features.append(feature_vector)\n","\n","# Convert the list of feature vectors into a numpy array\n","graph_features = np.array(graph_features)\n","\n","# Now you have the subgraph centrality feature for each graph, which you can use as input to your classifier.\n","print(len(graph_features[0]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"735zIPzhjIqk","executionInfo":{"status":"ok","timestamp":1716471804531,"user_tz":420,"elapsed":1394,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"e4e4bd50-6ad9-445d-d3e5-41cc4de7f514"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["200\n"]}]},{"cell_type":"markdown","source":["#real matrix"],"metadata":{"id":"-hESPoHCuAkX"}},{"cell_type":"code","source":["\n","# Applying the threshold function to X_train_matrices and X_test_matrices\n","X_train_thresholded = apply_threshold(X_train_matrices)\n","X_test_thresholded = apply_threshold(X_test_matrices)"],"metadata":{"id":"ZL4rqR9w5Mb3","executionInfo":{"status":"ok","timestamp":1717179838693,"user_tz":420,"elapsed":7843,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["import networkx as nx\n","import numpy as np\n","\n","def compute_graph_features(matrix):\n","    G = nx.from_numpy_array(matrix)  # Convert matrix to a NetworkX graph\n","\n","    # Calculate clustering coefficients\n","    clustering_coeffs = nx.clustering(G)\n","    clustering_values = list(clustering_coeffs.values())  # Convert dict values to list\n","\n","    # Calculate centrality measures\n","    degree_centrality = nx.degree_centrality(G)\n","    degree_values = list(degree_centrality.values())  # Convert dict values to list\n","\n","    # Laplacian spectrum (eigenvalues)\n","    laplacian_spectrum = nx.laplacian_spectrum(G)\n","    largest_eigenvalues = sorted(laplacian_spectrum.real)[-50:]  # take 50 largest eigenvalues, ensuring they are real\n","\n","    # Combine all features into a single feature vector\n","    feature_vector = np.concatenate([\n","        clustering_values,\n","        degree_values,\n","        largest_eigenvalues\n","    ])\n","\n","    return feature_vector\n","\n","# Compute features for each graph\n","train_features = [compute_graph_features(matrix) for matrix in X_train_thresholded]\n","test_features = [compute_graph_features(matrix) for matrix in X_test_thresholded]\n"],"metadata":{"id":"SiFVYC0Z9xm2","executionInfo":{"status":"ok","timestamp":1717182841728,"user_tz":420,"elapsed":101790,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qJnJSpevBjiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_features[0].shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMsvHa_B993J","executionInfo":{"status":"ok","timestamp":1717182852175,"user_tz":420,"elapsed":353,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"6971287d-9776-419a-f849-33adbb9c709d"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["(750,)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score, make_scorer\n","\n","originalclass = []\n","predictedclass = []\n","\n","def acc_score(y_true, y_pred):\n","    originalclass.extend(y_true)\n","    predictedclass.extend(y_pred)\n","    return accuracy_score(y_true, y_pred) # return accuracy score\n","\n","# clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n","# k_folds = KFold(n_splits = 5)\n","\n","# for kernel in ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']:\n","#   scores = cross_val_score(clf, X_train, y_train, cv = k_folds, scoring=make_scorer(acc_score))\n","#   print(f\"kernel {kernel}\")\n","#   print(classification_report(originalclass, predictedclass))"],"metadata":{"id":"TpuQ2nkmG-1l","executionInfo":{"status":"ok","timestamp":1717183575972,"user_tz":420,"elapsed":333,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"90zrBPYDG-yh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","# Convert lists to numpy arrays\n","X_train = np.array(train_features)\n","X_test = np.array(test_features)\n","\n","# Assuming y_train and y_test are already defined\n","y_train = np.array(y_train)  # Make sure y_train is correctly set\n","y_test = np.array(y_test)    # Make sure y_test is correctly set\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)  # Use the same scaler to transform test data\n","# Initialize the SVM classifier with an RBF kernel\n","svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')  # 'scale' uses 1 / (n_features * X.var()) as value of gamma\n","\n","# Train the model\n","svm_model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = svm_model.predict(X_test)"],"metadata":{"id":"nso4pswdBmIn","executionInfo":{"status":"ok","timestamp":1717182911463,"user_tz":420,"elapsed":1603,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","\n","# Initialize the SVM classifier\n","svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n","\n","# Perform 10-fold cross-validation\n","cv_scores = cross_val_score(svm_model, X_train, y_train, cv=10, scoring=make_scorer(acc_score))\n","print(classification_report(originalclass, predictedclass))\n","# Print the average score and standard deviation\n","print(\"CV Average Score: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTcQ69rWFqfa","executionInfo":{"status":"ok","timestamp":1717183586570,"user_tz":420,"elapsed":4161,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"18f97d60-8413-437c-ccde-f32637f9c34b"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.96      0.75       657\n","           1       0.43      0.05      0.09       411\n","\n","    accuracy                           0.61      1068\n","   macro avg       0.53      0.50      0.42      1068\n","weighted avg       0.55      0.61      0.50      1068\n","\n","CV Average Score: 0.61 (+/- 0.04)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GIiRe4TQG88z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.4f}')\n","\n","# Detailed classification report\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTS-xJkcFFQH","executionInfo":{"status":"ok","timestamp":1717183154958,"user_tz":420,"elapsed":832,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"e1238cc9-0ea2-429e-f1f2-4561d4626b47"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6975\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.99      0.82        82\n","           1       0.67      0.05      0.10        37\n","\n","    accuracy                           0.70       119\n","   macro avg       0.68      0.52      0.46       119\n","weighted avg       0.69      0.70      0.59       119\n","\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class SimpleNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.fc3 = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)  # No activation function here as we'll use CrossEntropyLoss which includes Softmax\n","        return x\n","\n","\n",""],"metadata":{"id":"ywmPAPGVL1R1","executionInfo":{"status":"ok","timestamp":1717184723870,"user_tz":420,"elapsed":333,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","# Convert numpy arrays to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Create datasets\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"LJVesgBCL5Jj","executionInfo":{"status":"ok","timestamp":1717184914907,"user_tz":420,"elapsed":2,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["# Setup model, loss, and optimizer\n","model = SimpleNN(input_size=X_train.shape[1], hidden_size=128, num_classes=2)  # Adjust num_classes as needed\n","model.train()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training loop\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    for data, targets in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zxvTf5rMuA1","executionInfo":{"status":"ok","timestamp":1717185088225,"user_tz":420,"elapsed":3904,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"a9fcaaf8-7664-410c-9441-dbeb457149b0"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 0.6649\n","Epoch [2/20], Loss: 0.5915\n","Epoch [3/20], Loss: 0.5223\n","Epoch [4/20], Loss: 0.4260\n","Epoch [5/20], Loss: 0.4426\n","Epoch [6/20], Loss: 0.2892\n","Epoch [7/20], Loss: 0.1912\n","Epoch [8/20], Loss: 0.1922\n","Epoch [9/20], Loss: 0.3364\n","Epoch [10/20], Loss: 0.0662\n","Epoch [11/20], Loss: 0.3426\n","Epoch [12/20], Loss: 0.0810\n","Epoch [13/20], Loss: 0.0629\n","Epoch [14/20], Loss: 0.0229\n","Epoch [15/20], Loss: 0.0382\n","Epoch [16/20], Loss: 0.0319\n","Epoch [17/20], Loss: 0.0164\n","Epoch [18/20], Loss: 0.0041\n","Epoch [19/20], Loss: 0.0038\n","Epoch [20/20], Loss: 0.0096\n"]}]},{"cell_type":"code","source":["model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, targets in test_loader:\n","        outputs = model(data)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f'Accuracy: {accuracy:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMDDoPhgMxaz","executionInfo":{"status":"ok","timestamp":1717185092945,"user_tz":420,"elapsed":319,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"a82a0e2a-1972-420c-8d0d-2d36900b8bb0"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 65.55%\n"]}]},{"cell_type":"markdown","source":["#big model"],"metadata":{"id":"e2Ucb24G4yJf"}},{"cell_type":"code","source":["# Step 1: Retrieve adjacency matrices\n","csv_file = '/content/pearsonr.csv'\n","adjacency_matrices = retrieve_adjacency_matrix(csv_file)\n","\n","# Step 2: Apply threshold\n","thresholded_matrices = apply_threshold(adjacency_matrices)"],"metadata":{"id":"7vDy9XJBvvds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import networkx as nx\n","from collections import Counter\n","\n","def retrieve_adjacency_matrix(csv_file):\n","    df = pd.read_csv(csv_file)\n","    filenames = df['File']\n","    labels = df['DX'].tolist()\n","    values = df.drop(['File', 'ScanDir ID', 'DX'], axis=1).values\n","\n","    adjacency_matrices = []\n","    for i in range(len(filenames)):\n","        upper_triangle_values = values[i][~np.isnan(values[i])]\n","        n = int(np.sqrt(2 * len(upper_triangle_values) + 0.25) - 0.5)\n","        adjacency_matrix = np.zeros((n, n))\n","\n","        row = 0\n","        for j in range(n):\n","            for k in range(j + 1, n):\n","                # Check if the current element is on the diagonal\n","                if j == k:\n","                    continue  # Skip setting diagonal elements\n","                adjacency_matrix[j, k] = upper_triangle_values[row]\n","                row += 1\n","        adjacency_matrices.append((filenames[i], adjacency_matrix, labels[i]))\n","\n","    return adjacency_matrices\n","\n","def apply_threshold(adjacency_matrices):\n","    thresholded_matrices = []\n","    for filename, matrix, label in adjacency_matrices:\n","        thresholded_matrix = np.where((matrix > 0.7) | (matrix < -0.7), 1, 0)\n","        thresholded_matrices.append((filename, thresholded_matrix, label))\n","    return thresholded_matrices\n","def compute_graph_features(graph):\n","    # Degree Distribution\n","    degree_distribution = list(dict(graph.degree()).values())\n","\n","    # Clustering Coefficient\n","    clustering_coefficient = nx.average_clustering(graph)\n","\n","    # Graph Spectra (Eigenvalues)\n","\n","    eigenvalues = nx.adjacency_spectrum(graph)\n","    eigenvalues_real = eigenvalues.real  # Extract real part of eigenvalues\n","\n","    return degree_distribution, clustering_coefficient\n","\n","# Step 3: Convert binary adjacency matrices to NetworkX graphs and compute graphlet counts\n","csv_file = '/content/pearsonr.csv'\n","adjacency_matrices = retrieve_adjacency_matrix(csv_file)\n","\n","# Step 2: Apply threshold\n","thresholded_matrices = apply_threshold(adjacency_matrices)\n","\n","# Step 3: Compute graph features\n","graph_features = []\n","for filename, matrix, label in thresholded_matrices:\n","    G = nx.from_numpy_array(matrix)\n","    degree_distribution, clustering_coefficient = compute_graph_features(G)\n","    # Create feature vector\n","    feature_vector = np.concatenate((degree_distribution, [clustering_coefficient], eigenvalues))\n","    graph_features.append((filename, feature_vector, label))\n","\n","# Now `graph_features` contains the filenames, graph features, and labels for each graph\n","# You can use these features for classification tasks."],"metadata":{"id":"RptIFpvUrcMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(graph_features[0][1].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3FJ5NQ2tCJ5","executionInfo":{"status":"ok","timestamp":1716478263351,"user_tz":420,"elapsed":415,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"eb97704b-4f44-4d00-b4ff-f5bb8cf76911"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(701,)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Separate features and labels\n","X = np.array([features[1] for features in graph_features])  # Extract feature vectors\n","y = np.array([features[2] for features in graph_features])  # Extract labels\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train the SVM model\n","svm_model = SVC(kernel='linear')\n","svm_model.fit(X_train, y_train)\n","\n","# Predict labels for the test set\n","y_pred = svm_model.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLqy1MMFCbw1","executionInfo":{"status":"ok","timestamp":1716478711866,"user_tz":420,"elapsed":21,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"886496d8-829e-4b0b-e919-f536c80de8af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.4375\n"]}]},{"cell_type":"markdown","source":["#dgl"],"metadata":{"id":"4f4jJiOTucjp"}},{"cell_type":"markdown","source":["##loed data"],"metadata":{"id":"nO3RH5o_wMV6"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","def retrieve_adjacency_matrix(csv_file):\n","    df = pd.read_csv(csv_file)\n","    filenames = df['File']\n","    labels = df['DX'].tolist()\n","    values = df.drop(['File', 'ScanDir ID', 'DX'], axis=1).values\n","\n","    adjacency_matrices = []\n","    for i in range(len(filenames)):\n","        upper_triangle_values = values[i][~np.isnan(values[i])]\n","        n = int(np.sqrt(2 * len(upper_triangle_values) + 0.25) - 0.5)\n","        adjacency_matrix = np.zeros((n, n))\n","\n","        row = 0\n","        for j in range(n):\n","            for k in range(j + 1, n):\n","                if j == k:\n","                    continue\n","                adjacency_matrix[j, k] = upper_triangle_values[row]\n","                row += 1\n","        adjacency_matrices.append((filenames[i], adjacency_matrix, labels[i]))\n","\n","    return adjacency_matrices\n","\n","def apply_threshold(adjacency_matrices):\n","    thresholded_matrices = []\n","    for filename, matrix, label in adjacency_matrices:\n","        thresholded_matrix = np.where((matrix > 0.7) | (matrix < -0.7), 1, 0)\n","        thresholded_matrices.append((filename, thresholded_matrix, label))\n","    return thresholded_matrices\n","\n","\n"],"metadata":{"id":"NW3YOCKQCjg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Retrieve adjacency matrices\n","csv_file = '/content/pearsonr.csv'\n","adjacency_matrices = retrieve_adjacency_matrix(csv_file)\n","\n","# Step 2: Apply threshold\n","thresholded_matrices = apply_threshold(adjacency_matrices)"],"metadata":{"id":"srbQhLp6wK8T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["preproces data to  can load in dgl"],"metadata":{"id":"eTA0qOZjwjw2"}},{"cell_type":"code","source":["!pip install dgl\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"seCsR1lPxK6D","executionInfo":{"status":"ok","timestamp":1716557064632,"user_tz":420,"elapsed":92598,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"0871d59c-9cb1-4590-e717-19f856594559"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dgl\n","  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Collecting torchdata>=0.5.0 (from dgl)\n","  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchdata, dgl\n","Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torchdata-0.7.1\n"]}]},{"cell_type":"markdown","source":["#instaling Dgl"],"metadata":{"id":"MK4UpQ4U3xRC"}},{"cell_type":"code","source":["%%capture\n","!git clone https://github.com/joerg84/Graph_Powered_ML_Workshop.git\n","!rsync -av Graph_Powered_ML_Workshop/ ./ --exclude=.git\n","!pip3 install dgl\n","!pip3 install numpy\n","!pip3 install torch\n","!pip3 install networkx\n","!pip3 install matplotlib"],"metadata":{"id":"CoNFbr2936dm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline"],"metadata":{"id":"QyuHFh3K3-op"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!git clone https://github.com/joerg84/Graph_Powered_ML_Workshop.git\n","!rsync -av Graph_Powered_ML_Workshop/ ./ --exclude=.git\n"],"metadata":{"id":"lU71w5Bw8x9m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install dgl numpy torch networkx matplotlib\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpI3f0sk82zG","executionInfo":{"status":"ok","timestamp":1716576832253,"user_tz":420,"elapsed":9063,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"61eaca38-8ff0-468e-ae2c-39cace059a91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip uninstall -y dgl\n","!pip install dgl\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"he4ZqZQ79UPx","executionInfo":{"status":"ok","timestamp":1716576946471,"user_tz":420,"elapsed":13877,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"51a23863-ac11-43db-9377-c90c4d69cd08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: dgl 2.1.0\n","Uninstalling dgl-2.1.0:\n","  Successfully uninstalled dgl-2.1.0\n","Collecting dgl\n","  Using cached dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl) (12.5.40)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n","Installing collected packages: dgl\n","Successfully installed dgl-2.1.0\n"]}]},{"cell_type":"code","source":["import itertools\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import dgl\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dgl.nn.pytorch import GraphConv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":575},"id":"I8BY9q_j4BxG","executionInfo":{"status":"error","timestamp":1716580409237,"user_tz":420,"elapsed":8298,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"f2803620-5d57-48f6-f525-db6362375611"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'DILL_AVAILABLE' from 'torch.utils.data.datapipes.utils.common' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/utils/common.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6d6ac53c528d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_backend\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/dataloading/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preferred_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pytorch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspot_target\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_dataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbatch_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPUCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheterograph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDGLGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/distributed/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexit_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_dataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistGraphServer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph_partition_book\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphPartitionBook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPartitionPolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/distributed/dist_graph.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphbolt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheterograph_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mempty_shared_mem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mETYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/graphbolt/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ffi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mminibatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/graphbolt/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_datapipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterDataPipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdata/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatapipes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mjanitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjanitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdata/datapipes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataChunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional_datapipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"DataChunk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"functional_datapipe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utils\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdata/datapipes/iter/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbz2fileloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBz2FileLoaderIterDataPipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mBz2FileLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m from torchdata.datapipes.iter.util.cacheholder import (\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mEndOnDiskCacheHolderIterDataPipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mEndOnDiskCacheHolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mInMemoryCacheHolderIterDataPipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mInMemoryCacheHolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdata/datapipes/iter/util/cacheholder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mportalocker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_unpickable_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDILL_AVAILABLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraverse_dps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'DILL_AVAILABLE' from 'torch.utils.data.datapipes.utils.common' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/utils/common.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["#finish part"],"metadata":{"id":"a_ORXaVJ31b5"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import dgl\n","import torch\n","import scipy.sparse as sp\n","from torch.utils.data import Dataset\n","from dgl.dataloading import GraphDataLoader\n","import dgl.nn.pytorch as dglnn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","def convert_to_dgl_graphs(thresholded_matrices):\n","    graphs = []\n","    labels = []\n","    for filename, matrix, label in thresholded_matrices:\n","        g = dgl.from_scipy(sp.csr_matrix(matrix))\n","        num_nodes = g.number_of_nodes()\n","        g.ndata['feat'] = torch.eye(num_nodes)  # Using identity matrix as node features\n","        graphs.append(g)\n","        labels.append(label)\n","    return graphs, torch.tensor(labels)\n","\n","graphs, labels = convert_to_dgl_graphs(thresholded_matrices)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"id":"0OYM_OsUwSyH","executionInfo":{"status":"error","timestamp":1716558514036,"user_tz":420,"elapsed":413,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"8099e19a-32bd-408e-f878-bd78b35c1421"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '_C' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-17401e7dffaf>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Backend and logging should be imported before other modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menable_verbose_logging\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_backend\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m from . import (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mload_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_preferred_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/backend/__init__.py\u001b[0m in \u001b[0;36mload_backend\u001b[0;34m(mod_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#     it already depends on both the backend framework and the DGL C library.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pytorch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mraise\u001b[0m  \u001b[0;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class GraphDataset(Dataset):\n","    def __init__(self, graphs, labels):\n","        self.graphs = graphs\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.graphs)\n","\n","    def __getitem__(self, idx):\n","        return self.graphs[idx], self.labels[idx]\n","\n","dataset = GraphDataset(graphs, labels)\n","dataloader = GraphDataLoader(\n","    dataset,\n","    batch_size=1024,\n","    drop_last=False,\n","    shuffle=True\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"V18NvwbRwi5p","executionInfo":{"status":"error","timestamp":1716556897872,"user_tz":420,"elapsed":6266,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"c7c3c80e-d3b1-4883-d615-75042b6eb43e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a8d7fc93bce2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGraphDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwindows\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madamw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msparse_adam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madamax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0masgd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mASGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sparse_adam.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_functional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maximize_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SparseAdam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import dgl\n","import torch\n","import scipy.sparse as sp\n","from torch.utils.data import Dataset\n","from dgl.dataloading import GraphDataLoader\n","import dgl.nn.pytorch as dglnn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# Define functions to process your data\n","def retrieve_adjacency_matrix(csv_file):\n","    df = pd.read_csv(csv_file)\n","    filenames = df['File']\n","    labels = df['DX'].tolist()\n","    values = df.drop(['File', 'ScanDir ID', 'DX'], axis=1).values\n","\n","    adjacency_matrices = []\n","    for i in range(len(filenames)):\n","        upper_triangle_values = values[i][~np.isnan(values[i])]\n","        n = int(np.sqrt(2 * len(upper_triangle_values) + 0.25) - 0.5)\n","        adjacency_matrix = np.zeros((n, n))\n","\n","        row = 0\n","        for j in range(n):\n","            for k in range(j + 1, n):\n","                if j == k:\n","                    continue\n","                adjacency_matrix[j, k] = upper_triangle_values[row]\n","                row += 1\n","        adjacency_matrices.append((filenames[i], adjacency_matrix, labels[i]))\n","\n","    return adjacency_matrices\n","\n","def apply_threshold(adjacency_matrices):\n","    thresholded_matrices = []\n","    for filename, matrix, label in adjacency_matrices:\n","        thresholded_matrix = np.where((matrix > 0.7) | (matrix < -0.7), 1, 0)\n","        thresholded_matrices.append((filename, thresholded_matrix, label))\n","    return thresholded_matrices\n","\n","def convert_to_dgl_graphs(thresholded_matrices):\n","    graphs = []\n","    labels = []\n","    for filename, matrix, label in thresholded_matrices:\n","        g = dgl.from_scipy(sp.csr_matrix(matrix))\n","        num_nodes = g.number_of_nodes()\n","        g.ndata['feat'] = torch.eye(num_nodes)  # Using identity matrix as node features\n","        graphs.append(g)\n","        labels.append(label)\n","    return graphs, torch.tensor(labels)\n","\n","class GraphDataset(Dataset):\n","    def __init__(self, graphs, labels):\n","        self.graphs = graphs\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.graphs)\n","\n","    def __getitem__(self, idx):\n","        return self.graphs[idx], self.labels[idx]\n","\n","class Classifier(nn.Module):\n","    def __init__(self, in_dim, hidden_dim, n_classes):\n","        super(Classifier, self).__init__()\n","        self.conv1 = dglnn.GraphConv(in_dim, hidden_dim)\n","        self.conv2 = dglnn.GraphConv(hidden_dim, hidden_dim)\n","        self.classify = nn.Linear(hidden_dim, n_classes)\n","\n","    def forward(self, g, h):\n","        h = F.relu(self.conv1(g, h))\n","        h = F.relu(self.conv2(g, h))\n","        with g.local_scope():\n","            g.ndata['h'] = h\n","            hg = dgl.mean_nodes(g, 'h')\n","            return self.classify(hg)\n","\n","# Load and process the data\n","csv_file = '/content/pearsonr.csv'\n","adjacency_matrices = retrieve_adjacency_matrix(csv_file)\n","thresholded_matrices = apply_threshold(adjacency_matrices)\n","graphs, labels = convert_to_dgl_graphs(thresholded_matrices)\n","\n","# Create dataset and dataloader\n","dataset = GraphDataset(graphs, labels)\n","dataloader = GraphDataLoader(\n","    dataset,\n","    batch_size=1024,\n","    drop_last=False,\n","    shuffle=True\n",")\n","\n","# Initialize and train the model\n","in_dim = graphs[0].ndata['feat'].shape[1]\n","hidden_dim = 20\n","n_classes = len(set(labels.tolist()))\n","\n","model = Classifier(in_dim, hidden_dim, n_classes)\n","opt = optim.Adam(model.parameters())\n","\n","for epoch in range(20):\n","    for batched_graph, labels in dataloader:\n","        feats = batched_graph.ndata['feat']\n","        logits = model(batched_graph, feats)\n","        loss = F.cross_entropy(logits, labels)\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"id":"XNsVyXPxw4JG","executionInfo":{"status":"error","timestamp":1716558536399,"user_tz":420,"elapsed":415,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"e84e6a3c-6df7-4582-83b2-f115d6583877"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '_C' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-b1b6ed3c1d75>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Backend and logging should be imported before other modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menable_verbose_logging\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_backend\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m from . import (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mload_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_preferred_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/backend/__init__.py\u001b[0m in \u001b[0;36mload_backend\u001b[0;34m(mod_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#     it already depends on both the backend framework and the DGL C library.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pytorch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mraise\u001b[0m  \u001b[0;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"]}]},{"cell_type":"markdown","source":["#another way"],"metadata":{"id":"sezoodyOTX0C"}},{"cell_type":"code","source":["!pip install networkx\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2xwtk4NUQNT","executionInfo":{"status":"ok","timestamp":1716582955616,"user_tz":420,"elapsed":11512,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"f096552d-3cb3-422a-d872-55deb39a1103"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n"]}]},{"cell_type":"code","source":["import networkx as nx\n","import numpy as np\n","\n","def convert_to_networkx_graphs(thresholded_matrices):\n","    graphs = []\n","    labels = []\n","    for filename, matrix, label in thresholded_matrices:\n","        # Create an empty NetworkX graph\n","        g = nx.Graph()\n","        num_nodes = matrix.shape[0]\n","\n","        # Add nodes to the graph\n","        g.add_nodes_from(range(num_nodes))\n","\n","        # Add edges to the graph based on the adjacency matrix\n","        for i in range(num_nodes):\n","            for j in range(i + 1, num_nodes):\n","                if matrix[i, j] == 1:  # Assuming thresholded matrix contains 0s and 1s\n","                    g.add_edge(i, j)\n","\n","        # Add node features (identity matrix for simplicity)\n","        node_features = np.eye(num_nodes)\n","\n","        # Add node features to the graph\n","        for node, features in enumerate(node_features):\n","            g.nodes[node]['feat'] = features\n","\n","        graphs.append(g)\n","        labels.append(label)\n","\n","    return graphs, np.array(labels)\n","\n","# Convert thresholded matrices to NetworkX graphs\n","graphs, labels = convert_to_networkx_graphs(thresholded_matrices)\n"],"metadata":{"id":"XphTtL88UOMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","class Classifier(nn.Module):\n","    def __init__(self, in_dim, hidden_dim, n_classes):\n","        super(Classifier, self).__init__()\n","        self.fc1 = nn.Linear(in_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, n_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Determine input dimension based on node features (e.g., size of identity matrix)\n","input_dim =350 # Assuming identity matrix as node features\n","hidden_dim = 20\n","output_dim = 5  # Number of classes\n","\n","model = Classifier(input_dim, hidden_dim, output_dim)\n","optimizer = optim.Adam(model.parameters())\n"],"metadata":{"id":"qGYO4TZyUl0V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert NetworkX graphs to PyTorch tensors\n","# Assume your DataLoader is ready, or you can create one similar to DGL DataLoader\n","\n","for epoch in range(100):\n","    for i, g in enumerate(graphs):\n","        features = torch.FloatTensor([g.nodes[node]['feat'] for node in g.nodes()])\n","        labels_tensor = torch.LongTensor([labels[i]])\n","\n","        optimizer.zero_grad()\n","        output = model(features)\n","        loss = F.cross_entropy(output, labels_tensor)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % print_every == 0:\n","            print('Epoch {}, Graph {}, Loss: {:.4f}'.format(epoch, i, loss.item()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"a1tQ42k7UwOZ","executionInfo":{"status":"error","timestamp":1716583211306,"user_tz":420,"elapsed":5,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"a953f805-a482-4212-8bf5-822a7e37f553"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Expected input batch_size (350) to match target batch_size (1).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-efbc688e5061>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (350) to match target batch_size (1)."]}]},{"cell_type":"markdown","source":["#classs clear"],"metadata":{"id":"zyRcwspmWby6"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F  # Add this line\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# Define a custom dataset class\n","class GraphDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        filename, adjacency_matrix, label = self.data[idx]\n","        adjacency_matrix = torch.FloatTensor(adjacency_matrix)\n","        # Map labels to binary (0 or 1)\n","        binary_label = torch.LongTensor([int(label != 0)])  # Convert non-zero labels to 1\n","        return adjacency_matrix, binary_label\n","\n","# Split data into training and testing sets\n","train_data, test_data = train_test_split(thresholded_matrices, test_size=0.2, random_state=42)\n","\n","# Create datasets and dataloaders\n","train_dataset = GraphDataset(train_data)\n","test_dataset = GraphDataset(test_data)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Define your graph classification model\n","class GraphClassifier(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GraphClassifier, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, start_dim=1)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# Define the dimensions for your model\n","input_dim = train_data[0][1].shape[0] * train_data[0][1].shape[1]  # Assuming adjacency matrices are square\n","hidden_dim = 64\n","output_dim = 2  # Binary classification\n","\n","# Initialize model, optimizer, and loss function\n","model = GraphClassifier(input_dim, hidden_dim, output_dim)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training loop\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    model.train()\n","    for batch in train_loader:\n","        adjacency_matrices, labels = batch\n","        optimizer.zero_grad()\n","        output = model(adjacency_matrices)\n","        loss = criterion(output, labels.squeeze())\n","        print(loss)\n","        loss.backward()\n","        optimizer.step()a\n","\n","    print(\"nnnnnnnnnnnnnnnn\")\n","    print(epoch)\n","\n","# Evaluation\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for batch in test_loader:\n","        adjacency_matrices, labels = batch\n","        output = model(adjacency_matrices)\n","        _, predicted = torch.max(output, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels.squeeze()).sum().item()\n","\n","print('Accuracy: {:.2f}%'.format(100 * correct / total))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOw3tQlfV7Tt","executionInfo":{"status":"ok","timestamp":1716617996348,"user_tz":420,"elapsed":19674,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"bfcab377-c616-42f8-c7d9-767d53a0b949"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.6859, grad_fn=<NllLossBackward0>)\n","tensor(4.6429, grad_fn=<NllLossBackward0>)\n","tensor(1.9701, grad_fn=<NllLossBackward0>)\n","tensor(4.1695, grad_fn=<NllLossBackward0>)\n","tensor(2.3494, grad_fn=<NllLossBackward0>)\n","tensor(0.8033, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","0\n","tensor(0.3451, grad_fn=<NllLossBackward0>)\n","tensor(0.4549, grad_fn=<NllLossBackward0>)\n","tensor(0.4606, grad_fn=<NllLossBackward0>)\n","tensor(0.9036, grad_fn=<NllLossBackward0>)\n","tensor(0.4896, grad_fn=<NllLossBackward0>)\n","tensor(0.4375, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","1\n","tensor(0.3254, grad_fn=<NllLossBackward0>)\n","tensor(0.3571, grad_fn=<NllLossBackward0>)\n","tensor(0.3638, grad_fn=<NllLossBackward0>)\n","tensor(0.3397, grad_fn=<NllLossBackward0>)\n","tensor(0.2965, grad_fn=<NllLossBackward0>)\n","tensor(0.2308, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","2\n","tensor(0.3117, grad_fn=<NllLossBackward0>)\n","tensor(0.2455, grad_fn=<NllLossBackward0>)\n","tensor(0.3893, grad_fn=<NllLossBackward0>)\n","tensor(0.2121, grad_fn=<NllLossBackward0>)\n","tensor(0.1252, grad_fn=<NllLossBackward0>)\n","tensor(0.0946, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","3\n","tensor(0.0852, grad_fn=<NllLossBackward0>)\n","tensor(0.1220, grad_fn=<NllLossBackward0>)\n","tensor(0.0619, grad_fn=<NllLossBackward0>)\n","tensor(0.0483, grad_fn=<NllLossBackward0>)\n","tensor(0.0406, grad_fn=<NllLossBackward0>)\n","tensor(0.0349, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","4\n","tensor(0.0177, grad_fn=<NllLossBackward0>)\n","tensor(0.0118, grad_fn=<NllLossBackward0>)\n","tensor(0.0075, grad_fn=<NllLossBackward0>)\n","tensor(0.0291, grad_fn=<NllLossBackward0>)\n","tensor(0.0094, grad_fn=<NllLossBackward0>)\n","tensor(0.0041, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","5\n","tensor(0.0033, grad_fn=<NllLossBackward0>)\n","tensor(0.0021, grad_fn=<NllLossBackward0>)\n","tensor(0.0004, grad_fn=<NllLossBackward0>)\n","tensor(0.0042, grad_fn=<NllLossBackward0>)\n","tensor(0.0008, grad_fn=<NllLossBackward0>)\n","tensor(0.0009, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","6\n","tensor(0.0007, grad_fn=<NllLossBackward0>)\n","tensor(0.0009, grad_fn=<NllLossBackward0>)\n","tensor(0.0010, grad_fn=<NllLossBackward0>)\n","tensor(0.0011, grad_fn=<NllLossBackward0>)\n","tensor(0.0011, grad_fn=<NllLossBackward0>)\n","tensor(0.0002, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","7\n","tensor(0.0005, grad_fn=<NllLossBackward0>)\n","tensor(0.0005, grad_fn=<NllLossBackward0>)\n","tensor(0.0004, grad_fn=<NllLossBackward0>)\n","tensor(0.0010, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","8\n","tensor(0.0003, grad_fn=<NllLossBackward0>)\n","tensor(0.0007, grad_fn=<NllLossBackward0>)\n","tensor(4.3851e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0004, grad_fn=<NllLossBackward0>)\n","tensor(4.9697e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","9\n","tensor(9.3534e-05, grad_fn=<NllLossBackward0>)\n","tensor(4.2745e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0002, grad_fn=<NllLossBackward0>)\n","tensor(0.0002, grad_fn=<NllLossBackward0>)\n","tensor(0.0002, grad_fn=<NllLossBackward0>)\n","tensor(0.0002, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","10\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(5.5635e-05, grad_fn=<NllLossBackward0>)\n","tensor(7.9817e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0002, grad_fn=<NllLossBackward0>)\n","tensor(3.3744e-05, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","11\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(3.6756e-05, grad_fn=<NllLossBackward0>)\n","tensor(2.8448e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0002, grad_fn=<NllLossBackward0>)\n","tensor(9.5934e-05, grad_fn=<NllLossBackward0>)\n","tensor(6.6848e-05, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","12\n","tensor(3.0176e-05, grad_fn=<NllLossBackward0>)\n","tensor(1.6439e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(5.7592e-05, grad_fn=<NllLossBackward0>)\n","tensor(7.8783e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","13\n","tensor(5.6491e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(4.3683e-05, grad_fn=<NllLossBackward0>)\n","tensor(3.2473e-05, grad_fn=<NllLossBackward0>)\n","tensor(2.6064e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","14\n","tensor(2.5835e-05, grad_fn=<NllLossBackward0>)\n","tensor(6.6418e-05, grad_fn=<NllLossBackward0>)\n","tensor(5.5489e-05, grad_fn=<NllLossBackward0>)\n","tensor(8.1061e-05, grad_fn=<NllLossBackward0>)\n","tensor(2.8250e-05, grad_fn=<NllLossBackward0>)\n","tensor(8.8748e-05, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","15\n","tensor(2.1314e-05, grad_fn=<NllLossBackward0>)\n","tensor(2.8667e-05, grad_fn=<NllLossBackward0>)\n","tensor(6.2111e-05, grad_fn=<NllLossBackward0>)\n","tensor(6.8731e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(2.5465e-05, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","16\n","tensor(1.9095e-05, grad_fn=<NllLossBackward0>)\n","tensor(4.6054e-05, grad_fn=<NllLossBackward0>)\n","tensor(1.0188e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(5.4096e-05, grad_fn=<NllLossBackward0>)\n","tensor(4.9374e-05, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","17\n","tensor(1.3291e-05, grad_fn=<NllLossBackward0>)\n","tensor(2.2613e-05, grad_fn=<NllLossBackward0>)\n","tensor(0.0001, grad_fn=<NllLossBackward0>)\n","tensor(2.5455e-05, grad_fn=<NllLossBackward0>)\n","tensor(7.8568e-05, grad_fn=<NllLossBackward0>)\n","tensor(1.5870e-05, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","18\n","tensor(6.5960e-05, grad_fn=<NllLossBackward0>)\n","tensor(1.7685e-05, grad_fn=<NllLossBackward0>)\n","tensor(6.5860e-06, grad_fn=<NllLossBackward0>)\n","tensor(8.3716e-05, grad_fn=<NllLossBackward0>)\n","tensor(2.3542e-05, grad_fn=<NllLossBackward0>)\n","tensor(6.2179e-05, grad_fn=<NllLossBackward0>)\n","nnnnnnnnnnnnnnnn\n","19\n","Accuracy: 77.08%\n"]}]},{"cell_type":"markdown","source":["#use graph"],"metadata":{"id":"amudRSFDDN8U"}},{"cell_type":"code","source":["pip install torch-geometric\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MecpWTjWEPXn","executionInfo":{"status":"ok","timestamp":1716645873116,"user_tz":420,"elapsed":17785,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"4250dca3-bde2-4081-e45e-76c09cd8f44c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","from torch_geometric.data import Data, DataLoader\n","\n","# Create a custom dataset\n","class GraphDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        filename, adjacency_matrix, label = self.data[idx]\n","        adjacency_matrix = torch.FloatTensor(adjacency_matrix)\n","        edge_index = torch.nonzero(adjacency_matrix, as_tuple=False).t().contiguous()\n","        x = torch.eye(adjacency_matrix.size(0))\n","        label = torch.LongTensor([label])\n","        return Data(x=x, edge_index=edge_index, y=label)\n","\n","# Prepare your dataset (using the thresholded_matrices from your code)\n","train_data, test_data = train_test_split(thresholded_matrices, test_size=0.2, random_state=42)\n","train_dataset = GraphDataset(train_data)\n","test_dataset = GraphDataset(test_data)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Define your GCN model\n","class GCN(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GCN, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, output_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","       # x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","# Initialize model, optimizer, and loss function\n","input_dim = train_data[0][1].shape[0]  # Number of nodes\n","hidden_dim = 64\n","output_dim = 2  # Binary classification\n","\n","model = GCN(input_dim, hidden_dim, output_dim)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_train_correct = 0\n","    total_train_samples = 0\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, data.y.squeeze())\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(output, 1)\n","        total_train_correct += (predicted == data.y.squeeze()).sum().item()\n","        total_train_samples += data.y.size(0)\n","\n","    # Evaluate on the testing dataset\n","    model.eval()\n","    total_test_correct = 0\n","    total_test_samples = 0\n","    with torch.no_grad():\n","        for data in test_loader:\n","            output = model(data)\n","            _, predicted = torch.max(output, 1)\n","            total_test_correct += (predicted == data.y.squeeze()).sum().item()\n","            total_test_samples += data.y.size(0)\n","\n","    # Compute and print accuracies\n","    train_accuracy = total_train_correct / total_train_samples\n","    test_accuracy = total_test_correct / total_test_samples\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"id":"5-uy2n1LXMTw","executionInfo":{"status":"error","timestamp":1716645883762,"user_tz":420,"elapsed":6779,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"a3d2c04c-9dbb-41d5-8877-ffbdeabc2004"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-ba32d3488ec7>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create a custom dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGraphDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.data import Data, DataLoader\n","from torch.utils.data import Dataset  # Import Dataset\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# Define a custom dataset class for PyTorch Geometric\n","class GraphDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        filename, adjacency_matrix, label = self.data[idx]\n","        adjacency_matrix = torch.FloatTensor(adjacency_matrix)\n","        # Convert non-zero labels to 1\n","        binary_label = torch.LongTensor([int(label != 0)])\n","        return Data(x=adjacency_matrix, edge_index=None), binary_label\n","\n","\n","# Split data into training and testing sets\n","train_data, test_data = train_test_split(thresholded_matrices, test_size=0.2, random_state=42)\n","\n","# Create datasets and dataloaders\n","train_dataset = GraphDataset(train_data)\n","test_dataset = GraphDataset(test_data)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Define the GCN model\n","class GCNClassifier(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GCNClassifier, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.relu(self.conv2(x, edge_index))\n","        x = torch.mean(x, dim=0)\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# Define dimensions\n","input_dim = train_data[0][1].shape[0]  # Number of features for each node\n","hidden_dim = 64\n","output_dim = 2  # Binary classification\n","\n","# Initialize model, optimizer, and loss function\n","model = GCNClassifier(input_dim, hidden_dim, output_dim)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_train_correct = 0\n","    total_train_samples = 0\n","    for data, labels in train_loader:\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, labels.squeeze())\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(output, 1)\n","        total_train_correct += (predicted == labels.squeeze()).sum().item()\n","        total_train_samples += labels.size(0)\n","\n","    # Evaluate on the testing dataset\n","    model.eval()\n","    total_test_correct = 0\n","    total_test_samples = 0\n","    with torch.no_grad():\n","        for data, labels in test_loader:\n","            output = model(data)\n","            _, predicted = torch.max(output, 1)\n","            total_test_correct += (predicted == labels.squeeze()).sum().item()\n","            total_test_samples += labels.size(0)\n","\n","    # Compute and print accuracies\n","    train_accuracy = total_train_correct / total_train_samples\n","    test_accuracy = total_test_correct / total_test_samples\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"id":"HkpuI3qRDtSa","executionInfo":{"status":"error","timestamp":1716646059724,"user_tz":420,"elapsed":2622,"user":{"displayName":"محمدامين نصرتي","userId":"06127324119802040333"}},"outputId":"e334792e-aa15-4b12-a733-cf13dac2785e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]},{"output_type":"error","ename":"ValueError","evalue":"`MessagePassing.propagate` only supports integer tensors of shape `[2, num_messages]`, `torch_sparse.SparseTensor` or `torch.sparse.Tensor` for argument `edge_index`.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-842bff658331>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-842bff658331>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_ba8ou_j5.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# End Propagate Forward Pre Hook ###########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mmutable_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mfuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_check_input\u001b[0;34m(self, edge_index, size)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    291\u001b[0m             ('`MessagePassing.propagate` only supports integer tensors of '\n\u001b[1;32m    292\u001b[0m              \u001b[0;34m'shape `[2, num_messages]`, `torch_sparse.SparseTensor` or '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: `MessagePassing.propagate` only supports integer tensors of shape `[2, num_messages]`, `torch_sparse.SparseTensor` or `torch.sparse.Tensor` for argument `edge_index`."]}]},{"cell_type":"code","source":[],"metadata":{"id":"2nOB3ULYFBCi"},"execution_count":null,"outputs":[]}]}